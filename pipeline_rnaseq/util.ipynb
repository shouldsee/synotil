{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Utilities for Visualising RNASeq. Author: Feng Geng (fg368@cam.ac.uk)\n",
    "#### Written for BrachyPhoton at SLCU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook tmp.ipynb to python\n",
      "[NbConvertApp] Writing 14774 bytes to tmp.py\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    !jupyter nbconvert --to python tmp.ipynb\n",
    "# !python compile_meta.ipynb && echo '[succ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = '/media/pw_synology3/BrachyPhoton/raw/index'\n",
    "OUTDIR = '/media/pw_synology3/BrachyPhoton/Mapped_data'\n",
    "# ! head {INDEX}\n",
    "\n",
    "import os,re,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymisca.vis_util as pyvis\n",
    "plt=pyvis.plt\n",
    "import pymisca.util as pyutil\n",
    "np = pyutil.np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "import sys\n",
    "modCurr = sys.modules[__name__]\n",
    "\n",
    "\n",
    "\n",
    "def readLines(fname):\n",
    "    with open(fname,'r') as f:\n",
    "        lines = [l.rstrip('\\n') for l in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "\n",
    "try:\n",
    "    INDIRs = [os.path.join(OUTDIR,l) for l in readLines(INDEX)]\n",
    "\n",
    "    ### remove the blacklisted samples\n",
    "    INDIRs = [ i for i in INDIRs if not bool(re.search(\"169R_12\", i))]\n",
    "except Exception as e:\n",
    "    print '[FAIL] to process index file:%s, due to %s'%(INDEX,e)\n",
    "\n",
    "\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\n",
    "    Source: https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "    \"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "    if base_cmap is None:\n",
    "        base = plt.get_cmap()\n",
    "    else:\n",
    "        base = plt.cm.get_cmap(base_cmap)\n",
    "    \n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "    \n",
    "def histTPM(df,COL='TPM'):\n",
    "    fig,axs= plt.subplots(1,2,figsize=[14,3])\n",
    "    vals = df[COL]\n",
    "    plt.sca(axs[0])\n",
    "    plt.hist(np.log1p(vals),30,log=0)\n",
    "    plt.vlines(1,0,6000)\n",
    "    plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "    plt.sca(axs[1])\n",
    "    plt.hist(vals,30,log=1)\n",
    "    plt.grid()\n",
    "#     plt.show()\n",
    "    \n",
    "def timePCA(M,ZTime):\n",
    "#     COL = meta[colorName]\n",
    "    COL_RGB,(COL_LAB,COL_LST) = ser2col(pd.Series(ZTime))\n",
    "    \n",
    "    fig,axs= plt.subplots(1,2,figsize=[14,4])\n",
    "\n",
    "    plt.sca(axs[0])    \n",
    "    labs = np.arange(len(M))\n",
    "    x = [int(x.lstrip('ZT')) for x in COL]\n",
    "    y = M[:,0]\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('PC1')\n",
    "    l = plt.scatter(x,y,c=COL_RGB,)\n",
    "    for i,(xx,yy,lab) in enumerate(zip(x,y,labs)):\n",
    "        plt.annotate(lab,xy=(xx,yy), )\n",
    "#     plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.sca(axs[1])    \n",
    "    y = M[:,1]\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('PC1')\n",
    "    l = plt.scatter(x,y,c=COL_RGB,)\n",
    "    for i,(xx,yy,lab) in enumerate(zip(x,y,labs)):\n",
    "        plt.annotate(lab,xy=(xx,yy), )\n",
    "#     plt.legend()\n",
    "    plt.grid()\n",
    "    return fig    \n",
    "def histoLine(xs,BINS=None,log= 0,**kwargs):\n",
    "    ys,edg = np.histogram(xs,BINS)\n",
    "    ct = (edg[1:] + edg[:-1])/2\n",
    "    if log:\n",
    "        ys = np.log1p(ys)\n",
    "    else:\n",
    "        pass\n",
    "    l =plt.plot(ct,ys,**kwargs)\n",
    "    return l\n",
    "def qc_Avg(C,axs = None,silent=1):\n",
    "    if axs is None:\n",
    "        if not silent:\n",
    "            fig,axs= plt.subplots(1,3,figsize=[14,3])\n",
    "    assert C.shape[1]<100\n",
    "    MEAN = C.mean(axis=1,keepdims=1).squeeze()\n",
    "    STD = C.std(axis=1,keepdims = 1).squeeze()\n",
    "    # plt.hist(X) \n",
    "    # plt.hist(X[1])\n",
    "    X = MEAN[None,:]\n",
    "\n",
    "    MIN,MAX = X.min(),np.percentile(X,99)\n",
    "    BINS = np.linspace(MIN,MAX,100)\n",
    "    CV = STD/MEAN\n",
    "    if not silent:\n",
    "        BX = np.linspace(*np.span(MEAN,99.9),num=30)\n",
    "        BY = np.linspace(*np.span(STD,99.9),num=50)\n",
    "        xlim = np.span(BX)\n",
    "        ylim = np.span(BY)\n",
    "        plt.sca(axs[0])\n",
    "        for i in range(1):\n",
    "            histoLine(X[i],BINS,alpha=0.4)\n",
    "\n",
    "        plt.grid(1)\n",
    "        plt.xlabel('$E(X)$')\n",
    "\n",
    "        plt.sca(axs[1])\n",
    "\n",
    "        i = 10000\n",
    "        idx = np.random.randint(len(MEAN),size=i)\n",
    "        x,y = MEAN[idx],STD[idx]\n",
    "        # plt.hist2d(MEAN.squeeze(),STD.squeeze(),(50,50))\n",
    "        # plt.show()\n",
    "        plt.plot(x,y,'.')\n",
    "        plt.grid(1)\n",
    "        abline()\n",
    "        plt.xlabel('$E(X)$')\n",
    "        plt.ylabel('$Std(X)$')\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "        plt.sca(axs[2])\n",
    "\n",
    "        ct,BX,BY = np.histogram2d(MEAN,STD,(BX,BY))\n",
    "        plt.pcolormesh(BX,BY,np.log1p(ct).T,)\n",
    "    #     plt.gca().matshow(np.log1p(ct),aspect='auto')\n",
    "        plt.xlabel('$E(X)$')\n",
    "        plt.ylabel('$Std(X)$')\n",
    "    return (MEAN,STD,CV),axs\n",
    "def qcAvg(*args,**kwargs):\n",
    "    '''Legacy support''' \n",
    "    return qc_Avg(*args,**kwargs)\n",
    "\n",
    "def qc_meanVar(C,clu,axs=None):\n",
    "    ''' C of shape (n_gene, n_condition)\n",
    "    Points colored by cluster\n",
    "    '''\n",
    "    clu = np.array(clu)\n",
    "    nClu = np.max(clu)+1\n",
    "    if axs is None:\n",
    "        fig,axs= plt.subplots(1,3,figsize=[14,3])\n",
    "    for ci in range(nClu):\n",
    "        idx = np.where(clu==ci)[0]\n",
    "        CC = C[idx,:]\n",
    "        STAT,axs = qcAvg(CC,axs=axs)\n",
    "    ax = axs[1]\n",
    "#     ax.set_alpha(0.5)\n",
    "    MEAN = C.mean(axis=1,keepdims=1).squeeze()\n",
    "    STD = C.std(axis=1,keepdims = 1).squeeze()\n",
    "    xlim = np.span(MEAN,99.)\n",
    "    ylim = np.span(STD,99.)\n",
    "    ax.set_xlim(0,5);ax.set_ylim(0,2)\n",
    "    return ((MEAN,STD,STD/MEAN),axs)\n",
    "    \n",
    "def matHist(X,idx=None,XLIM=[0,200],nbin=100):    \n",
    "    plt.figure(figsize=[12,4])\n",
    "    if idx is not None:\n",
    "        X = X[idx]\n",
    "    MIN,MAX = X.min(),np.percentile(X,99)\n",
    "    BINS = np.linspace(MIN,MAX,nbin)\n",
    "    for i in range(len(idx)):\n",
    "        histoLine(X[i],BINS,alpha=0.4,log=1)\n",
    "    plt.xlim(XLIM)\n",
    "    plt.grid()\n",
    "    \n",
    "def getCV(xs):\n",
    "    return np.std(xs)/np.mean(xs)\n",
    "\n",
    "def getCol(dfs,COLUMN='Coverage'):\n",
    "    ctraw = [df.get(COLUMN).values for df in dfs]\n",
    "#     ctraw = map(lambda x:getTPM(x,COL=COLUMN),dfs)\n",
    "    ctraw = np.array(ctraw)\n",
    "    return ctraw\n",
    "\n",
    "def abline(k=1,y0=0):\n",
    "    '''Add a reference line\n",
    "    '''\n",
    "    MIN,MAX=plt.gca().get_xlim()\n",
    "    f = lambda x: k*x+y0\n",
    "    plt.plot([MIN,MAX],[f(MIN),f(MAX)],'b--')\n",
    "    print MIN,MAX\n",
    "    \n",
    "def subset(dfs,idx):\n",
    "    return [df.iloc[idx] for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### I/O utility\n",
    "\n",
    "def combine_csv(fnames):\n",
    "    geneSet = set()\n",
    "    dfs = []\n",
    "    CUTOFF = 6\n",
    "\n",
    "    FCOL = 'Coverage'\n",
    "    geneAll = set()\n",
    "    geneAny = set()\n",
    "    geneRef = pd.DataFrame()\n",
    "    # for i,fname in enumerate(fnames[:10]):\n",
    "    for i,fname in enumerate(fnames):\n",
    "        if not i%10:\n",
    "            print 'Reading %s'%fname\n",
    "        df = pd.read_table(fname)\n",
    "        allGene = df['Gene ID']\n",
    "        exprGene = allGene.loc[df[FCOL]>CUTOFF]    \n",
    "\n",
    "        geneDiff = set(allGene).difference(geneAll)    \n",
    "        appd = df[allGene.isin(geneDiff)]\n",
    "\n",
    "        geneRef = geneRef.append(appd)\n",
    "\n",
    "        geneAll.update(allGene)\n",
    "        geneAny.update(exprGene)\n",
    "    #     break\n",
    "    #     if not geneAll:\n",
    "    #         geneAll.update(df['Gene ID'])\n",
    "    #     else:\n",
    "    #         geneSet.intersection_update(df['Gene ID'])\n",
    "        dfs.append(df)\n",
    "\n",
    "    geneRef.loc[:,['Coverage','FPKM','TPM']] = 0\n",
    "    geneRef.sort_values('Gene ID',inplace=1)\n",
    "    geneRef = geneRef.reset_index()\n",
    "    geneSet = geneAny\n",
    "    geneValid = geneRef[geneRef['Gene ID'].isin(geneSet)] \n",
    "\n",
    "    print 'Nmber of Genes before filtering:',len(geneAll)\n",
    "    print 'Nmber of Genes after filtering:',len(geneSet)\n",
    "    print 'Surviving rate: ',float(len(geneSet))/len(geneAll)\n",
    "    \n",
    "    return dfs,(geneRef,geneValid)\n",
    "def padWithRef(df,ref):\n",
    "    df = df.append(ref[~ref['Gene ID'].isin(df['Gene ID'])])\n",
    "    df.sort_values('Gene ID',inplace=1)\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "def routine_combineCSV(fnames):\n",
    "    print '[PROG] Starting to readfile'\n",
    "    dfs,(geneRef,geneValid) = combine_csv(fnames)\n",
    "    print '[PROG] Finished to readfile'\n",
    "    \n",
    "    print '[PROG] Starting to pad'\n",
    "    f = pyutil.functools.partial(padWithRef,ref=geneRef)\n",
    "    lst = pyutil.mp_map(f,dfs,n_cpu=1)\n",
    "\n",
    "    SHP = np.array([df.shape for df in lst])\n",
    "    assert np.all(SHP == SHP[0:1]),'Arrays not sharing shape:%s'%SHP\n",
    "    gids = np.array([df['Gene ID'] for df in lst])\n",
    "    assert np.all(gids == gids[0:1])\n",
    "    print '[PROG] Finished padding'\n",
    "    \n",
    "    dfs = lst\n",
    "    dfs = [df.iloc[geneValid.index] for df in dfs]\n",
    "    return dfs,(geneRef,geneValid.reset_index().drop('index',1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(C,std=1):\n",
    "    C = np.log1p(C)\n",
    "#     C = C[clu==1,:][:,meta_wt_LD.index]\n",
    "    C = (C-C.mean(axis=1,keepdims=1))\n",
    "    if std:\n",
    "        STD= C.std(axis=1,keepdims=1)\n",
    "        nonCst = (STD!=0).squeeze()\n",
    "        C[nonCst] = C[nonCst]/STD[nonCst]\n",
    "    return C\n",
    "\n",
    "\n",
    "def msgGMM(model = None, train_data = None,name='test',**kwargs):\n",
    "    mdl = model\n",
    "    s = '''\n",
    "Name:{name}\n",
    "Converged:{cvg}\n",
    "min_logL: {logL}\n",
    "(lower-bound of) MEAN logL :{mlogL}'''.format(\n",
    "        name=name,\n",
    "         cvg=mdl.converged_,\n",
    "         logL = mdl.lower_bound_,\n",
    "         mlogL=mdl.lower_bound_/len(train_data) if not train_data is None else mdl.lower_bound_\n",
    "                                )\n",
    "    return s\n",
    "\n",
    "# def sortLabel(Y,X,#return_pos=0\n",
    "#              ):\n",
    "#     ### Sorting by maximum\n",
    "# #         X = vX\n",
    "#     X  = X-X.mean(axis=1,keepdims=1)\n",
    "#     coord = np.arange(X.shape[-1])[None]\n",
    "#     wt_X = (X == X.max(axis=1,keepdims=1))*coord\n",
    "# #         wt_X = X * coord\n",
    "#     cis = list(range(max(Y)+1))\n",
    "#     pos =  [wt_X[Y == ci,:].mean() for ci in cis]\n",
    "#     sidx = np.argsort(pos)\n",
    "# #     if return_pos:\n",
    "# #         return pos[sidx]\n",
    "# #     else:\n",
    "#     pj = dict(zip(sidx,cis))\n",
    "#     Y = np.vectorize(pj.get)(Y)\n",
    "#     return Y,np.take(pos,sidx)\n",
    "def qcGMM(model,train_data,name='Test',valid_data = None,pt=None,axs = None,**kwargs):\n",
    "    mdl = model\n",
    "    X   = train_data\n",
    "    if valid_data is None:\n",
    "        valid_data = X\n",
    "    vX = valid_data\n",
    "    if axs is None:\n",
    "        fig,axs = plt.subplots(1,2,gridspec_kw={\"width_ratios\": (.1, .9),\n",
    "                                               'wspace':0.1,\n",
    "                                                'top':0.8\n",
    "    #                                             'hspace':0.5\n",
    "                                               },\n",
    "                              figsize=[14,3])\n",
    "    Y = mdl.predict(X)\n",
    "    s = mdl.score_samples(X)\n",
    "    \n",
    "\n",
    "    Y,pos = sortLabel(Y,X)\n",
    "    \n",
    "        \n",
    "    idx = np.argsort(Y)\n",
    "    if pt is not None:\n",
    "        ps = np.percentile(s, pt)\n",
    "        if pt > 50:\n",
    "            i2 = s[idx] > ps\n",
    "        else:\n",
    "            i2 = s[idx] < ps\n",
    "        im = vX[idx[i2]].T\n",
    "    else:\n",
    "        im = vX[idx].T\n",
    "        \n",
    "    ax = axs[0]\n",
    "    plt.sca(axs[0])        \n",
    "    ax.hist(s,50);\n",
    "    if pt is not None:\n",
    "        ax.vlines(ps,0,2000)\n",
    "    plt.grid()\n",
    "\n",
    "#     plt.sca(axs[1])\n",
    "    ax = axs[1]\n",
    "    ax.matshow(im,aspect='auto')\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.set_title(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook tmp.ipynb to python\n",
      "[NbConvertApp] Writing 19104 bytes to tmp.py\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    !jupyter nbconvert --to python tmp.ipynb\n",
    "# !python compile_meta.ipynb && echo '[succ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PCA utilities\n",
    "\n",
    "import pymisca.vis_util as pyvis\n",
    "def fit_PCA(C,n_components=5,**kwargs):\n",
    "    import sklearn.decomposition.pca as skpca\n",
    "    mdl = skpca.PCA(n_components=n_components,**kwargs)\n",
    "    M = mdl.fit_transform(C)\n",
    "    \n",
    "    return {'model':mdl,\n",
    "            'train_data':C,\n",
    "            'trans_data':M,}\n",
    "\n",
    "def quickPCA(trans_data=None,model=None,COL_SER=None,index=None,**kwargs):\n",
    "    M = trans_data\n",
    "    mdl = model\n",
    "    nSample =   len(M)\n",
    "    assert nSample < 100,'Too many samples in the maxtrix: %d>100'%nSample\n",
    "    \n",
    "#     labs = np.arange(nSample)\n",
    "    labs = index\n",
    "    vara = labs * 0. if mdl is None else mdl.explained_variance_ratio_\n",
    "\n",
    "    if not isinstance(COL_SER,pd.Series):\n",
    "        COL_SER = pd.Series(COL_SER)\n",
    "\n",
    "    \n",
    "    COL_RGB,(COL_LAB,COL_LST) = ser2col(COL_SER)\n",
    "    common = {\n",
    "             }\n",
    "    fig,axs= plt.subplots(1,2,figsize=[14,4])\n",
    "\n",
    "    def pc2d(pi,pj):\n",
    "        x, y  = M[:,pi],M[:,pj]\n",
    "        l = plt.scatter(x,y,c=COL_RGB,)\n",
    "        for _,(xx,yy,lab) in enumerate(zip(x,y,labs)):\n",
    "            plt.annotate(lab,xy=(xx,yy), )\n",
    "    #     plt.legend()\n",
    "        plt.grid()\n",
    "        plt.xlabel('PC%d(%.1f%%)'%(pi+1,vara[pi]*100))\n",
    "        plt.ylabel('PC%d(%.1f%%)'%(pj+1,vara[pj]*100))\n",
    "    plt.sca(axs[0])\n",
    "    pc2d(0,1)\n",
    "    plt.sca(axs[1])\n",
    "    pc2d(2,3)\n",
    "    recs = [pyvis.mpl.patches.Rectangle((0,0),1,1,fc=c) for c in COL_LST]\n",
    "    fig.legend(recs,COL_LAB)    \n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\n",
    "    Source: https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "    \"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "    if base_cmap is None:\n",
    "        base = plt.get_cmap()\n",
    "    else:\n",
    "        base = plt.cm.get_cmap(base_cmap)\n",
    "    \n",
    "    color_list = base(np.linspace(0, 1, N+1))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N+1)\n",
    "def ser2col(COL_SER):\n",
    "    COL_VAL, COL_LAB= COL_SER.factorize()\n",
    "    NCAT = len(COL_LAB)\n",
    "#     cmap = plt.get_cmap('jet')\n",
    "    cmap = discrete_cmap(NCAT,'jet')\n",
    "#     print (COL_VAL.ravel())\n",
    "    COL_RGB = cmap(COL_VAL.ravel())\n",
    "    COL_LST = cmap(range(NCAT))\n",
    "    return COL_RGB,(COL_LAB,COL_LST)\n",
    "\n",
    "    \n",
    "def timePCA(ZTime_int,trans_data=None, model = None,COL_SER=None,index=None,**kwargs):\n",
    "    mdl = model; M = trans_data\n",
    "#     COL = meta[colorName]\n",
    "    if COL_SER is None:\n",
    "        COL_SER = ZTime_int\n",
    "    COL_RGB,(COL_LAB,COL_LST) = ser2col(pd.Series(COL_SER))\n",
    "    \n",
    "    if index is None:\n",
    "        labs = np.arange(len(M))\n",
    "        print '[WARN] index not specified'\n",
    "    else:\n",
    "        labs = index\n",
    "    vara = labs * 0. if mdl is None else mdl.explained_variance_ratio_\n",
    "        \n",
    "    nPC = 4\n",
    "    fig,axs= plt.subplots(1,nPC,figsize=[14,4])\n",
    "        \n",
    "    for i in range(nPC):\n",
    "        pi = i\n",
    "        plt.sca(axs[i])    \n",
    "        x = ZTime_int\n",
    "        y = M[:,i]\n",
    "        plt.xlabel('ZTime')\n",
    "#         plt.ylabel('PC%d'%(i+1))\n",
    "        plt.ylabel('PC%d(%.1f%%)'%(pi+1,vara[pi]*100))\n",
    "        l = plt.scatter(x,y,c=COL_RGB,)\n",
    "\n",
    "        for i,(xx,yy,lab) in enumerate(zip(x,y,labs)):\n",
    "            plt.annotate(lab,xy=(xx,yy), )\n",
    "    #     plt.legend()\n",
    "        plt.grid()\n",
    "    recs = [pyvis.mpl.patches.Rectangle((0,0),1,1,fc=c) for c in COL_LST]\n",
    "    fig.legend(recs,COL_LAB)    \n",
    "\n",
    "    return fig    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Cannot find file:key.gene\n"
     ]
    }
   ],
   "source": [
    "#### Cluster Profiling Utilities\n",
    "fname = 'key.gene'\n",
    "try:\n",
    "    geneKey = pd.read_table(fname)\n",
    "except:\n",
    "    print \"[WARN] Cannot find file:%s\"%fname\n",
    "    geneKey = None\n",
    "\n",
    "def findMarker(df,concise=1,silent = 0,geneKey=geneKey,how='inner'):\n",
    "    ''' \"geneKey\" needs to have at least 'Gene Name' and 'Bio Name' \n",
    "    '''\n",
    "    import IPython.display as ipd\n",
    "    if not isinstance(df,pd.DataFrame):\n",
    "        df = pd.DataFrame({'Gene Name': df,'Gene ID':df})\n",
    "    df = df.reset_index().merge(geneKey,how=how).set_index('index')\n",
    "    df = df.rename(columns={'Gene ID':'Hit ID',\n",
    "                       'Gene Name':'Query ID'})\n",
    "    if concise:\n",
    "#         df = df[['Hit ID',u'Query ID',u'Bio Name', u'Major role', u'Type of gene']]\n",
    "        df = df[['Hit ID',u'Query ID',u'Bio Name']]\n",
    "#         df = df[['Hit ID',u'Query ID',u'Bio Name', u'Major role', u'Type of gene']]\n",
    "    if not silent:\n",
    "        print '[MARKER] Found %d/%d' %(sum(~df['Hit ID'].isnull()),len(geneKey))\n",
    "        ipd.display(df)\n",
    "    return df\n",
    "\n",
    "def mapTup(lst,n):\n",
    "    res = [x[:n] for x in lst]\n",
    "    return res\n",
    "def isNovo(lst):\n",
    "    res = map(lambda x:x=='STRG',mapTup(lst,4))\n",
    "    return res\n",
    "def countNovo(df,):\n",
    "    res = pyutil.collections.Counter([])\n",
    "    return res\n",
    "\n",
    "def meta2name(meta,keys=['gtype','light','Age','ZTime']):\n",
    "    res = pyutil.paste0([meta[k] for k in keys],'_')\n",
    "    return res\n",
    "\n",
    "def qc_GeneExpr(exprMat,idx=None,\n",
    "               gene=None,gRef=None,id_col='Gene Name',\n",
    "                show_ytick = None,\n",
    "               condName=None,**kwargs):\n",
    "    if idx is None:\n",
    "        assert not(gene is None or gRef is None),'Must specify \"gene\" and \"meta\" when \"idx\" not provided'\n",
    "        ### Query dataframe with id\n",
    "        qRes = pyutil.gQuery(gene,gRef,id_col=id_col)\n",
    "        idx = qRes.index\n",
    "    show_ytick = show_ytick or len(idx)<=100\n",
    "    if gene is not None:\n",
    "        ytick = gene.values \n",
    "    elif gRef is not None:\n",
    "        ytick = gRef.loc[idx][id_col]\n",
    "    else:\n",
    "        ytick = idx\n",
    "        print '[WARN] ytick not defined'\n",
    "    \n",
    "    if condName is None:\n",
    "        xtick = None\n",
    "    elif isinstance(condName,pd.DataFrame):\n",
    "        xtick = meta2name(condName)\n",
    "    else:\n",
    "        xtick = condName\n",
    "    ax = pyvis.heatmap(exprMat[idx],\n",
    "                       xlab='Sample ID',ylab='Gene',\n",
    "                       xtick = xtick,\n",
    "                       ytick = ytick if show_ytick else None,**kwargs\n",
    "                      )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdNorm(X):\n",
    "    X = meanNorm(X).copy()\n",
    "    STD = np.std(X,axis=1,keepdims=1); pos = np.squeeze(STD>0);\n",
    "    X[pos] = X[pos]/STD[pos]\n",
    "    return X\n",
    "def meanNorm(X):\n",
    "    X = (X-X.mean(axis=1,keepdims=1))\n",
    "    return X\n",
    "def ctNorm(X):\n",
    "    X = (X-X.mean(axis=1,keepdims=1))\n",
    "    return X\n",
    "def identityNorm(X):\n",
    "    return X\n",
    "def fit_BGM_AllNorm(C,normLst=None,algoLst=None,ALI='Test',**kwargs):\n",
    "    if normLst is None:\n",
    "        normLst = [stdNorm,meanNorm,ctNorm,identityNorm]\n",
    "    if algoLst is None:\n",
    "        algoLst = ['DPGMM','DDGMM','GMM',]\n",
    "    mdls = {}\n",
    "    for normF in normLst:\n",
    "        mdls[normF.__name__] = fit_BGM(C,normF=normF,\n",
    "                                       ALI=ALI,\n",
    "                                       algoLst = algoLst,\n",
    "                                       **kwargs)\n",
    "#     np.save(ALI,mdls,)        \n",
    "    return mdls\n",
    "\n",
    "\n",
    "def fit_BGM(C,\n",
    "            ALI = 'Test',\n",
    "            normF = identityNorm,\n",
    "            stdPer = 0,\n",
    "            rowName=None,\n",
    "            colName=None,\n",
    "            nClu = 30,\n",
    "            maxIt = 250,\n",
    "           algoLst = None):\n",
    "    if algoLst is None:\n",
    "        algoLst = ['DPGMM','DDGMM','GMM',]    \n",
    "    try:\n",
    "        DIR,ALI = ALI.rsplit('/',1)\n",
    "    except:\n",
    "        DIR='.'\n",
    "    os.system('mkdir -p %s'%(DIR))\n",
    "    if isinstance(C,pd.DataFrame):\n",
    "        rowName,colName,C = C.index.values, C.columns, C.values        \n",
    "        pass\n",
    "    if stdPer > 0 :\n",
    "        assert stdPer < 100,'Percentile must < 100, Got %d instead'%stdPer\n",
    "        (MEAN,STD,CV),_ = qc_Avg(C)\n",
    "        pIdx = STD > np.percentile(STD, stdPer)        \n",
    "        rowName = np.array(rowName)[pIdx]; C = C[pIdx]\n",
    "        \n",
    "    import sklearn.mixture as skmix\n",
    "    common = {'n_components': nClu,\n",
    "          'verbose':2,\n",
    "         'max_iter':maxIt,}\n",
    "    alpha = .1\n",
    "    mdlLst = {'DPGMM':skmix.BayesianGaussianMixture(weight_concentration_prior_type='dirichlet_process',\n",
    "                                        weight_concentration_prior=alpha,\n",
    "                                       **common),\n",
    "          'GMM':skmix.GaussianMixture(**common),\n",
    "          'DDGMM':skmix.BayesianGaussianMixture(weight_concentration_prior_type='dirichlet_distribution',\n",
    "                                        weight_concentration_prior=alpha,\n",
    "                                       **common),\n",
    "         }\n",
    "    mdls = {}\n",
    "    X = normF(C)\n",
    "#     raise Exception('test')\n",
    "    for mdlName,mdl in mdlLst.items():\n",
    "        if mdlName not in algoLst:\n",
    "            continue\n",
    "        NAME = '%s_stdPer=%d_norm=%s_genre=%s_nClu=%d_maxIt=%d'%(\n",
    "            ALI,\n",
    "            stdPer,\n",
    "            normF.__name__,\n",
    "            mdlName,\n",
    "            mdl.n_components,\n",
    "            maxIt\n",
    "        )\n",
    "        print '[MSG] Now Fitting Model:%s'%NAME\n",
    "        d = {'name': NAME,\n",
    "             'train_data':X,\n",
    "             'colName':colName,\n",
    "             'rowName':rowName,\n",
    "             'param':{\n",
    "                 'stdPer':stdPer,\n",
    "                 'normF':normF.__name__,\n",
    "                 'nClu':mdl.n_components,\n",
    "                 'genre':mdlName,\n",
    "             },\n",
    "           }\n",
    "        try:\n",
    "            logFile = open('%s/%s.log'%(DIR,NAME),'w')\n",
    "            with pyutil.RedirectStdStreams(logFile):\n",
    "                mdl.fit(X)\n",
    "                d.update({'suc':1,'model':mdl})\n",
    "#             logFile.close()\n",
    "            print \"[SUCC] to fit Model:%s\"%(NAME,)\n",
    "        except Exception as e:\n",
    "            print \"[FAIL] to fit Model:%s due to :'%s'\"%(NAME,e)\n",
    "            d.update({'suc':0})\n",
    "        mdls[NAME] = d    \n",
    "        np.save('%s/%s'%(DIR,NAME),d)\n",
    "    return mdls\n",
    "def make_qc_Model(vX,tX=None,normF = None):\n",
    "\n",
    "    ##### Datasets: Training\n",
    "#     vX = None\n",
    "    ##### vX: Validation dataset\n",
    "#     vX = vX[clu==1,:][:,msort[msort['light']=='SD'][msort['Age_int']==2][msort].index]\n",
    "#     vX = util.preprocess(vX,std=1)\n",
    "#     print normF,type(normF)\n",
    "    def qc_Model(#model,train_data,\n",
    "                suc=1,\n",
    "                 name='Test',pt=None,\n",
    "                normF_override=normF,\n",
    "                tX=tX,\n",
    "        **d):\n",
    "        if not suc:\n",
    "            print '[]Skipping failed Model %s'%name\n",
    "            return \n",
    "        print msgGMM(name=name,**d)    \n",
    "        fig,axs = plt.subplots(3,2,gridspec_kw={\"width_ratios\": (.1, .9),\n",
    "                                                   'wspace':0.1,\n",
    "                                                    'hspace':0.5,\n",
    "                                                    'top':0.8\n",
    "                                                   },\n",
    "                                  figsize=[14,6])\n",
    "        normF = normF_override or getattr(modCurr, name.split('_')[0])\n",
    "        if tX is None:\n",
    "            tX = kwargs['train_data']\n",
    "#         if tX is None:\n",
    "#             tX = kwargs['X']\n",
    "        axc= axs[0]\n",
    "        dname = 'Datasets-Training_'\n",
    "        qcGMM(valid_data=normF(tX),pt=pt,axs=axc,name=dname+name,**d)\n",
    "        axc= axs[1]\n",
    "        dname = 'Datasets-Validation_'\n",
    "        qcGMM(valid_data=normF(vX),pt=pt,axs=axc,name=dname+name,**d)\n",
    "        \n",
    "        axc= axs[2]\n",
    "        dname = 'Datasets-ValidMinusTraining'\n",
    "        vD = normF(tX)-normF(vX)\n",
    "#         vD = -(normF(tX)-normF(vX))\n",
    "        qcGMM(valid_data=vD,pt=pt,axs=axc,name=dname+name,**d)\n",
    "        \n",
    "    return qc_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc_Sort(fname=None,df=None,cname = 'test',vmin=-2,vmax=2,title = None,**heatargs):\n",
    "    if df is None:\n",
    "        df = pyutil.readData(fname)\n",
    "        if title is None:\n",
    "            title = '[file]%s'%fname\n",
    "    heatargs.update(\n",
    "        {'vmin':vmin,\n",
    "         'vmax':vmax,\n",
    "         'cname':cname,\n",
    "        }    )\n",
    "    C = df.values\n",
    "    (M,V,CV),_= qcAvg(C,silent=0)\n",
    "    plt.suptitle(title)\n",
    "    inter = -len(C)//1000\n",
    "    fig,axs= plt.subplots(3,1,figsize=[14,6],gridspec_kw={'hspace':0.3})\n",
    "    axs=axs.flat\n",
    "    pyvis.heatmap(C[V.argsort()][::inter],transpose=1,\n",
    "                 main='sorted by Varaince',ax=axs[0],**heatargs)\n",
    "\n",
    "    pyvis.heatmap(C[CV.argsort()][::inter],transpose=1,\n",
    "                 main='sorted by CV',ax=axs[1],**heatargs)\n",
    "\n",
    "    pyvis.heatmap(C[M.argsort()][::inter],transpose=1,\n",
    "                 main='sorted by Average',ax=axs[2],**heatargs)\n",
    "    return fig,axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'sortLabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-bf6f2b27e210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# from countMatrix import countMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mcountMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0msortLabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# import countMatrix;reload(countMatrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# from countMatrix import countMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'sortLabel'"
     ]
    }
   ],
   "source": [
    "class countMatrix(pyutil.util_obj):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(countMatrix, self).__init__(**kwargs)\n",
    "    @classmethod\n",
    "    def from_npy(cls,fname):\n",
    "        dd = np.load(fname).tolist()\n",
    "        return cls(**dd)\n",
    "    def colName_short(self,condName=None):\n",
    "        condName = self.colName if condName is None else condName        \n",
    "        try:\n",
    "            condName = pyutil.meta2flat([ \n",
    "                [x[1] for x in y] \n",
    "                    for y in pyutil.flat2meta(condName)],\n",
    "                seps=['_'])\n",
    "        except Exception as e:\n",
    "            print '\\n \\[WARN\\] unable to simplify condName. Exception:%s'%e\n",
    "        finally:\n",
    "            return condName\n",
    "    def heatmap(self,C=None,vlim=[-2,2],**kwargs):\n",
    "        C = self.train_data if C is None else C\n",
    "        condName = self.colName_short()\n",
    "#         im = pyvis.heatmap(C[cidx][sidx],\n",
    "        im = pyvis.heatmap(C,\n",
    "#                            ylab=(None if not i else 'Gene'),\n",
    "#                            ytick = (None if not i else gCur['Gene Name']),\n",
    "                           xlab='Condition',\n",
    "                           xtick=condName,\n",
    "                           transpose=1,\n",
    "                          vmin=vlim[0],vmax=vlim[1],\n",
    "#                           ax=ax\n",
    "                          ) \n",
    "        return im\n",
    "def loadMatrix(fname):\n",
    "    ali, ext = fname.rsplit('.',1)\n",
    "    if ext == 'npy':\n",
    "        dd = np.load(fname).tolist()\n",
    "    return dd\n",
    "import countMatrix as ctMat\n",
    "# from countMatrix import countMatrix\n",
    "countMatrix = ctMat.countMatrix\n",
    "sortLabel = ctMat.sortLabel\n",
    "# import countMatrix;reload(countMatrix)\n",
    "# from countMatrix import countMatrix\n",
    "\n",
    "def qc_ModelDict(dd=None,fname=None,ali=None,geneKey=None,DIR=None,\n",
    "                 clu = None,cluMax = 100,\n",
    "                 vlim= None\n",
    "                ):\n",
    "    if isinstance(geneKey,dict ):\n",
    "        geneKey = pd.Dataframe.from_dict(geneKey)\n",
    "        geneKey[1] = geneKey.index; \n",
    "        geneKey.rename(columns={0:'Bio Name',\n",
    "                                1:'Gene Name'})\n",
    "    if dd is None:\n",
    "        dd = countMatrix.from_npy(fname)\n",
    "        ali = fname.rsplit('.',1)[0]\n",
    "        \n",
    "    if dd.suc ==0:\n",
    "        print '[WARN] this model is empty due to a failure %s'%dd['name']\n",
    "        return\n",
    "    if vlim is None:\n",
    "        vlim = np.span(dd.train_data,p=99.9)\n",
    "#         geneKey.rename({})\n",
    "    sper = 0\n",
    "#     ali = NBNAME+'_h%d_'%75+\n",
    "    if ali is not None:\n",
    "        ali = ali.rsplit('/',1)[-1]\n",
    "    else:\n",
    "        ali = dd.__dict__.get('name','test')\n",
    "        if isinstance(ali,list):\n",
    "            ali = ':'.join(ali)\n",
    "    DIR = os.path.abspath(DIR or '.')\n",
    "    \n",
    "#     os.system('mkdir -p %s/src'%DIR)\n",
    "#     os.system('mkdir -p %s'%DIR)\n",
    "    print '[ALI]',DIR,'/',ali\n",
    "    \n",
    "    mdl,tX = dd.model,dd.train_data; tXsd = stdNorm(tX)\n",
    "    gRef,condName = dd.rowName,dd.colName_short()\n",
    "    \n",
    "    #### Process rowName\n",
    "    gRef = pd.DataFrame({'Gene Name':gRef,'Gene ID':gRef})\n",
    "    if geneKey is not None:\n",
    "        gRef = findMarker(gRef, geneKey=geneKey,silent=1,how='left',concise=1)\n",
    "        gRef['isMarker']=~gRef['Bio Name'].isnull()\n",
    "        gRef = gRef.rename(columns={'Query ID':'Gene Name'}).drop('Hit ID',1)\n",
    "        print '[GREF]',len(gRef)\n",
    "    \n",
    "    if isinstance(mdl,list):\n",
    "        print dd.nCol\n",
    "        tX = tX[:,:dd.nCol[0]]; nidx = np.isnan(tX[:,0])\n",
    "        mdl = mdl[0]\n",
    "        if any(nidx):        \n",
    "            tX,nX = tX[~nidx],tX[nidx]; nn = sum(nidx)\n",
    "            Y = mdl.predict(tX); s = mdl.score_samples(tX); \n",
    "            Y,pos = sortLabel(Y,tX)\n",
    "            Y = np.hstack([Y,[max(Y)+1]*nn]); s = np.hstack([s,[-1]*nn]); sbin = s> np.percentile(s,sper); \n",
    "            print tX.shape,sbin.shape\n",
    "        else:\n",
    "            Y = mdl.predict(tX); s = mdl.score_samples(tX); sbin = s> np.percentile(s,sper); \n",
    "            Y,pos = sortLabel(Y,tX)\n",
    "        tX = dd.train_data\n",
    "    else:\n",
    "        Y = mdl.predict(tX); s = mdl.score_samples(tX); sbin = s> np.percentile(s,sper); \n",
    "        Y,pos = sortLabel(Y,tX)\n",
    "    \n",
    "    \n",
    "    # pcommon= {}\n",
    "    try:\n",
    "        os.system('mkdir -p %s/%s'%(DIR,ali))\n",
    "#         _ , ali = ali.rsplit('/',1)\n",
    "        CWD= os.getcwd()\n",
    "        _ = os.chdir('%s/%s'%(DIR,ali))\n",
    "        os.system('mkdir -p src/')\n",
    "        OFILE = open('main.md','w')\n",
    "        ExcelFile= pd.ExcelWriter('main.xlsx', engine='xlsxwriter')\n",
    "        with pyutil.RedirectStdStreams(OFILE):\n",
    "#             print dd.param\n",
    "            parDF = dd.param if isinstance(dd.param, list) else [dd.param]\n",
    "            parDF = pd.DataFrame(parDF)\n",
    "#             print '[pAss]'\n",
    "            print '\\n',pyutil.pd2md(parDF)\n",
    "#             for k,v in .items():\n",
    "#                 print '%s:%s\\n'%(k,v)\n",
    "            print 'Directory: %s \\n \\n  Model Name: %s'%(DIR,ali)\n",
    "            print '\\n [.xlsx](main.xlsx)',\n",
    "            print '[.tar.gz](main.tar.gz)',\n",
    "            for clu in range(-1,max(Y)+1):\n",
    "                if clu==cluMax:\n",
    "                    break \n",
    "                fig,axs = plt.subplots(2,1,figsize=[max(7,min(14,len(tX)/3.)),\n",
    "                                                   max(5,min(18,len(tX.T)/1.5))],\n",
    "                                       sharex='all',\n",
    "                                     gridspec_kw={'bottom':0.28,'top':0.8,\n",
    "                                                 'left':0.2}\n",
    "                                     )        \n",
    "                if clu == -1:\n",
    "#                     Y,pos = sortLabel(Y,tX)\n",
    "                    cidx = Y>-1                    \n",
    "                    gCur = gRef[cidx]\n",
    "                    sidx = np.argsort(Y);gCur = gCur.iloc[sidx]\n",
    "                    cluName = 'background.gene'\n",
    "                else:\n",
    "                    cidx = Y==clu \n",
    "                    cidx = cidx & sbin\n",
    "                    gCur = gRef[cidx]\n",
    "                    sidx = np.argsort(s[cidx])[::-1];gCur = gCur.iloc[sidx]\n",
    "                    cluName = 'clu%03d.gene'%(clu)\n",
    "                print '\\n Cluster:%d'%(clu),'\\n','Gene Count:%d'%len(gCur)\n",
    "                if len(gCur)==0:\n",
    "                    continue\n",
    "                    \n",
    "#                 gCur = pd.DataFrame({'Gene Name':gCur})\n",
    "#                 if clu>=0:\n",
    "                if geneKey is not None:\n",
    "                    gMark = gCur[gCur['isMarker']==1]\n",
    "#                     gMark = findMarker(gCur['Gene Name'],geneKey=geneKey,silent=1,how='right')\n",
    "                    gMark.to_excel(ExcelFile,cluName,index=True,startcol=2)       \n",
    "                    print '\\n',pyutil.pd2md(gMark)\n",
    "#                     gCur = gMark\n",
    "#                     gCur = gMark.rename(columns={'Query ID':'Gene Name'})                \n",
    "                gCur[['Gene Name']].to_csv('src/%s'%cluName,index=0,)\n",
    "                gCur[['Gene Name']].to_excel(ExcelFile,cluName,index=True,)                \n",
    "                \n",
    "                figList = []\n",
    "                matDict ={'raw':tX,'stdNorm':tXsd}\n",
    "                sheet_curr = ExcelFile.sheets[cluName]\n",
    "                for i,k in enumerate(['raw','stdNorm']):\n",
    "                    C = matDict[k]; ax =axs[i]                    \n",
    "                    im = pyvis.heatmap(C[cidx][sidx],\n",
    "                                       ylab=(None if not i else 'Gene'),\n",
    "                                       ytick = (None if not i else gCur['Gene Name']),\n",
    "                                       xlab='Condition',xtick=condName,transpose=1,\n",
    "                                      vmin=vlim[0],vmax=vlim[1],\n",
    "                                      ax=ax\n",
    "                                      )  \n",
    "                    dd.addBox(ax=ax)\n",
    "#                     figList +=[FFname]\n",
    "                    \n",
    "                    plt.colorbar(im)\n",
    "                    plt.title(k)\n",
    "                plt.suptitle('Cluster %d'%clu,y=1)\n",
    "#                 try:\n",
    "#                 fig.tight_layout()\n",
    "#                 except:\n",
    "#                     print '\\n \\[WARN\\] tight_layout() failed, legend may not display properly'\n",
    "#                     pass                \n",
    "                FFname = 'src/clu%03d.png'%(clu,)\n",
    "                FigMd = pyutil.showsavefig(fname=FFname)\n",
    "                print '\\n',(FigMd) ## remove directory name                \n",
    "                sheet_curr.insert_image(0, 7, FFname)                \n",
    "                plt.show()\n",
    "                plt.close()\n",
    "        \n",
    "        ExcelFile.save()\n",
    "        ExcelFile.close()\n",
    "        os.system('pdext {fname} html'.format(fname=OFILE.name) )\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "        raise e\n",
    "    finally:\n",
    "        os.chdir(CWD)\n",
    "#     os.chdir(sys.path[0])\n",
    "#     os.system('pdext {ali}.md pdf'.format(ali=ali) )\n",
    "def log2p1(x):\n",
    "    res = np.log2(x+1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DataSets Management\n",
    "def dfContrast(dfRef,dfObs):\n",
    "    ''' Contrast two DataFrames\n",
    "    '''\n",
    "    C = dfObs.values - dfRef.values\n",
    "    df = pd.DataFrame(C); df.set_index(dfObs.index,inplace=1)\n",
    "    df.columns = pyutil.metaContrast(dfRef.columns,dfObs.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook tmp.ipynb to python\n",
      "[NbConvertApp] Writing 31429 bytes to tmp.py\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    !jupyter nbconvert --to python tmp.ipynb\n",
    "# !python compile_meta.ipynb && echo '[succ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001', '003', '004', '005']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['001','005','003','004'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
