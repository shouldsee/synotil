{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# Usage: (python) preprocessor.py /path/to/FASTQ_DIR\n",
    "# Example: preprocessor.py /media/pw_synology3/PW_HiSeq_data/RNA-seq/Raw_data/testONLY/133R/BdPIFs-32747730/133E_23_DN-40235206\n",
    "# Purpose: Download fastq files from the supplied path and \n",
    "#    combine them into R1.fastq and R2.fastq\n",
    "# \n",
    "# Created:7  OCT 2016, Hui@SLCU map-RNA-seq.py\n",
    "# Update: 11 Feb 2017. Hui@SLCU\n",
    "# Update: 29 May 2018. Feng@SLCU preprocessor.py\n",
    "\n",
    "\n",
    "import tempfile,subprocess\n",
    "import os, sys, datetime, glob, re\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# shellexec = os.system\n",
    "\n",
    "def check_all_samples(d):\n",
    "    '''\n",
    "    [Deprecated] Use LeafFiles(DIR) instead, kept for a reference\n",
    "    Recursively walking a directory tree\n",
    "    TBM to return useful output\n",
    "    '''\n",
    "    for k in sorted(d.keys()):\n",
    "        rpath = d[k]\n",
    "        result = check_directory(rpath)\n",
    "        if result != '':\n",
    "            print('%s:%s [%s]' % (k, rpath, result))\n",
    "            rpath = rpath.rstrip('/')\n",
    "            if glob.glob(rpath) is []: # rpath does not exist or it is an incomplete path\n",
    "                path_lst = glob.glob(rpath + '*/')\n",
    "                assert len(path_lst) == 1,'Found multiple directories under %s'%rpath\n",
    "                rpath = path_lst[0]\n",
    "                d[k] = rpath.rstrip('/') # update rpath\n",
    "\n",
    "\n",
    "\n",
    "def nTuple(lst,n,silent=1):\n",
    "    \"\"\"ntuple([0,3,4,10,2,3], 2) => [(0,3), (4,10), (2,3)]\n",
    "    \n",
    "    Group a list into consecutive n-tuples. Incomplete tuples are\n",
    "    discarded e.g.\n",
    "    \n",
    "    >>> group(range(10), 3)\n",
    "    [(0, 1, 2), (3, 4, 5), (6, 7, 8)]\n",
    "    \"\"\"\n",
    "    if not silent:\n",
    "        L = len(lst)\n",
    "        if L % n != 0:\n",
    "            print '[WARN] nTuple(): list length %d not of multiples of %d, discarding extra elements'%(L,n)\n",
    "    return zip(*[lst[i::n] for i in range(n)])\n",
    "\n",
    "def LinesNotEmpty(sub):\n",
    "    sub = [ x for x in sub.splitlines() if x]\n",
    "    return sub\n",
    "\n",
    "def LeafFiles(DIR):\n",
    "    ''' Drill down to leaf files of a directory tree if the path is unique.\n",
    "    '''\n",
    "    assert os.path.exists(DIR),'%s not exist'%DIR\n",
    "    DIR = DIR.rstrip('/')\n",
    "    if not os.path.isdir(DIR):\n",
    "        return [DIR]\n",
    "    else:\n",
    "        cmd = 'ls -LR %s'%DIR\n",
    "        res = subprocess.check_output(cmd,shell=1)\n",
    "        res = re.split(r'([^\\n]*):',res)[1:]\n",
    "        it = nTuple(res,2,silent=0)\n",
    "        DIR, ss = it[0];\n",
    "        for dd,ss in it[1:]:\n",
    "            NEWDIR, ALI = dd.rsplit('/',1)\n",
    "            assert NEWDIR == DIR, 'Next directory %s not contained in %s'%(dd,DIR)\n",
    "            DIR = dd \n",
    "        res = [ '%s/%s'%(DIR,x) for x in LinesNotEmpty(ss)]\n",
    "        return res                \n",
    "\n",
    "retype = type(re.compile('hello, world'))\n",
    "def revSub(ptn, dict):\n",
    "    '''Reverse filling a regex matcher.\n",
    "    Adapted from: https://stackoverflow.com/a/13268043/8083313\n",
    "'''\n",
    "    if isinstance(ptn, retype):\n",
    "        ptn = ptn.pattern\n",
    "    ptn = ptn.replace(r'\\.','.')\n",
    "    replacer_regex = re.compile(r'''\n",
    "        \\(\\?P         # Match the opening\n",
    "        \\<(.+?)\\>\n",
    "        (.*?)\n",
    "        \\)     # Match the rest\n",
    "        '''\n",
    "        , re.VERBOSE)\n",
    "    res = replacer_regex.sub( lambda m : dict[m.group(1)], ptn)\n",
    "    return res\n",
    "\n",
    "def write_log(fname, s):\n",
    "    f = open(fname, 'a')\n",
    "    f.write(s + '\\n')\n",
    "    f.close()\n",
    "\n",
    "def gnuPara(cmd,debug=0,ncore = 6):\n",
    "    '''\n",
    "    [Deprecated] Bad and does not wait for tasks to finish\n",
    "    '''\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=True) if not debug else open('temp.sh','w')\n",
    "    with tmp as tmp:\n",
    "        print cmd\n",
    "        tmp.write(cmd)\n",
    "        E = shellexec('parallel --gnu -j%d <%s &>>parallel.log'%(\n",
    "            ncore,\n",
    "            tmp.name\n",
    "            )\n",
    "        )\n",
    "    return E\n",
    "\n",
    "def mp_para(f,lst,ncore = 6):\n",
    "    if ncore ==1:\n",
    "        res = map(f,lst)\n",
    "    else:\n",
    "        p = mp.Pool(ncore)\n",
    "        res = p.map_async(f,lst,)\n",
    "        res = res.get(10000000)\n",
    "        p.close()\n",
    "    return res\n",
    "\n",
    "datenow = lambda: datetime.datetime.now().strftime(\"%Y_%m_%d_%H:%M:%S\")\n",
    "\n",
    "#### Regex for downloaded .fastq(.gz) files\n",
    "# PTN = re.compile('(?P<lead>.*)_S(?P<sample>\\d{1,3})_L(?P<chunk>\\d+)_R(?P<read>[012])_(?P<trail>\\d{1,4})\\.(?P<ext>.+)')\n",
    "PTN = re.compile('(?P<lead>.*)_L(?P<chunk>\\d+)_R(?P<read>[012])_(?P<trail>\\d{1,4})\\.(?P<ext>.+)')\n",
    "\n",
    "\n",
    "def shellexec(cmd,debug=0):\n",
    "    print(cmd) \n",
    "    if not debug:\n",
    "        return subprocess.call(cmd,shell=1)\n",
    "#         return os.system(cmd)\n",
    "\n",
    "def process_rna_sample(samplePATH, debug=0):\n",
    "    '''\n",
    "    Pull together raw reads from an input folder\n",
    "    Args:\n",
    "        samplePATH: Folder of .fastq(.gz) fot. be processed\n",
    "    Comment: Refactored based on Hui's map-RNA-seq.py process_rna_sample().    \n",
    "    '''\n",
    "    #     return os.system('/bin/bash -c `%s`'%cmd)\n",
    "    #     cmd = '/bin/bash -c `%s`'%cmd\n",
    "\n",
    "    #     return subprocess.call(cmd,env=os.environ,cwd=os.getcwd(),\n",
    "    #                           shell=True)\n",
    "    \n",
    "\n",
    "    samplePATH = samplePATH.rstrip('/')\n",
    "    shellexec('echo $SHELL')\n",
    "    \n",
    "    RNA_SEQ_MAP_FILE = 'some-script.sh'\n",
    "    DESTINATION_DIR  ='\"/path/to/output/\"' \n",
    "    WORKING_DIR='.'\n",
    "    \n",
    "    # Create a temporary directory \n",
    "    os.system('mkdir -p %s'%WORKING_DIR)\n",
    "    temp_dir = os.path.join(WORKING_DIR,\n",
    "                            '%s-%s'%(\n",
    "                                os.path.basename(samplePATH),\n",
    "                                datenow(),\n",
    "                            )\n",
    "    )\n",
    "    os.system('mkdir -p %s'%temp_dir)\n",
    "\n",
    "    #### Download raw read .fastq from samplePATH\n",
    "#     print samplePATH\n",
    "    FILES = glob.glob('%s/*' % samplePATH)\n",
    "    FILES = sum(map(LeafFiles,FILES),[])\n",
    "#     ccmd = '%s/* -t %s'%(samplePATH,temp_dir) \n",
    "    ccmd = '%s -t %s'%(' '.join(FILES), temp_dir) \n",
    "    cmd1 = 'cp -lr %s'%ccmd; \n",
    "    cmd2 = 'cp -r %s'%ccmd\n",
    "    shellexec(cmd1) ==0 or shellexec(cmd2) \n",
    "    ODIR = os.getcwd()\n",
    "    print '[ODIR]',ODIR\n",
    "    try:\n",
    "        os.chdir(temp_dir) #     shellexec('cd %s'%temp_dir)\n",
    "\n",
    "        #### Parse .fastq filenames and assert quality checks\n",
    "        if debug:\n",
    "            FS = [x.rsplit('/')[-1] for x in  FILES]\n",
    "            print FS[:5]\n",
    "#             FS = [x[pL+1:] for x in FILES]\n",
    "#             FS = FILES\n",
    "    #         assert 0\n",
    "        else:\n",
    "            FS = glob.glob('*')\n",
    "        BUF = '\\n'.join(FS)\n",
    "        PARSED = [{'fname':m.group(0),'data':m.groupdict()} for m in re.finditer(PTN,BUF)]\n",
    "        for d in PARSED:\n",
    "            d['data']['fname'] = d['fname']\n",
    "        data = [x['data'] for x in PARSED]\n",
    "        meta = pd.DataFrame(data)\n",
    "        meta = check_L004(meta)\n",
    "        \n",
    "        if debug:\n",
    "            return meta\n",
    "        else:\n",
    "            unzipAndConcat(meta)\n",
    "#             print '\\n\\n[BUF]',BUF\n",
    "#             print PARSED\n",
    "#             return data\n",
    "#         meta =  pd.DataFrame(index = data)\n",
    "\n",
    "#         R1 = [d for d in PARSED if d['data']['read']=='1']\n",
    "#         R2 = [d for d in PARSED if d['data']['read']=='2']\n",
    "#         Rboth = R1+R2\n",
    "#         common_names = set(d['data']['lead'] for d in Rboth)\n",
    "#         assert len(common_names) == 1,'Common leading strings are not unique: %s' % common_names\n",
    "#         common_name = common_names.pop()\n",
    "#         alias = common_name\n",
    "\n",
    "#         CHU1=sorted(d['data']['chunk'] for d in R1)\n",
    "#         CHU2=sorted(d['data']['chunk'] for d in R2)\n",
    "#         assert  CHU1 == CHU2,'Counts of R1/R2 chunks disagree, R1:%s R2:%s '%(CHU1,CHU2) \n",
    "#         assert len(CHU1) >= 4,'Counts of R1/R2 chunks: Actual %d Expected: >= 4 ' %len(CHU1) \n",
    "\n",
    "#         R1name = sorted((d['fname'] for d in R1),)\n",
    "#         R2name = sorted((d['fname'] for d in R2),)\n",
    "#         print R1name,'\\n',R2name ### debug printout\n",
    "\n",
    "#         #### Unzip where required\n",
    "#         FS = [F for F in [d['fname'] for d in Rboth] if F.endswith('gz')]\n",
    "#         cmd = '\\n'.join(['gzip -d <%s >%s; sleep 0'% (F,F.rstrip('.gz')) \n",
    "#                          if not os.path.exists(F.rstrip('.gz')) \n",
    "#                          else '## gzip -d skipped since fastq exists for %s' % F for F in FS])\n",
    "\n",
    "#     #     gnuPara(cmd,debug=0,ncore= 1)\n",
    "#         mp_para(shellexec,cmd.splitlines(),ncore=NCORE)\n",
    "#         R1name = [n.rstrip('.gz') for n in R1name]\n",
    "#         R2name = [n.rstrip('.gz') for n in R2name]    \n",
    "\n",
    "#         cmd = 'cat %s >%s_R1_raw.fastq' % (' '.join(R1name)  ,alias)\n",
    "#         cmd +='\\ncat %s >%s_R2_raw.fastq' % (' '.join(R2name),alias)\n",
    "#         shellexec(cmd)\n",
    "\n",
    "        print '[DONE!]:%s'%samplePATH\n",
    "        samplePATH = samplePATH.rstrip('/')\n",
    "#         idPath = '/'.join(samplePATH.split('/')[-3:])\n",
    "        ptn = '[\\^/](\\d{1,4}[RC][_/].*)'\n",
    "        idPath = re.findall(ptn,samplePATH)[0]\n",
    "        os.system('echo %s >OLDDIR'%idPath)\n",
    "#         exit(0)\n",
    "    except Exception as e:        \n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "        raise e\n",
    "    finally:\n",
    "        os.chdir(ODIR)\n",
    "    print '[[WTFFF1]]'\n",
    "    #### Stop here\n",
    "    return temp_dir\n",
    "\n",
    "def check_L004(meta):\n",
    "    g = meta.groupby(['lead','read'],as_index=0)\n",
    "    ct = g.count()\n",
    "\n",
    "    mout = meta.merge(ct[['lead','read','chunk']] ,on=['lead','read'],suffixes=['','_count'])\n",
    "    idx = mout['chunk_count'] ==4\n",
    "    if not idx.all():\n",
    "        print '[WARN] following reads are discarded due to chunk_count != 4'\n",
    "        print mout[~idx][['fname','chunk']] \n",
    "        mout = mout[idx]\n",
    "    return mout\n",
    "def unzipAndConcat(meta,debug= 0):\n",
    "    idx= [x.endswith('gz') for x in meta['ext']]\n",
    "    if any(idx):\n",
    "        #### unzip .gz where applicable\n",
    "        mcurr = meta.iloc[idx]\n",
    "        cmds = [cmd_ungzip(x) for x in mcurr['fname']]\n",
    "        if debug:\n",
    "            print cmds[:1]\n",
    "        else:\n",
    "            mp_para(shellexec,cmds, ncore=NCORE)            \n",
    "        #### Remove .gz in DataFrame accordingly\n",
    "        meta.loc[idx,'ext'] = [ x.rstrip('.gz')  for x in mcurr['ext'] ]\n",
    "\n",
    "    ### Map metas to fnames after decompression \n",
    "    mapper = lambda x: revSub(PTN,x)\n",
    "    meta['fname'] = meta.apply(mapper,axis=1)\n",
    "    g = meta.groupby('lead')\n",
    "    cmds = [cmd_combineFastq(x[1]['fname']) for x in g]\n",
    "    if debug:\n",
    "        print cmds[:1]\n",
    "    else:\n",
    "        mp_para( shellexec,cmds, ncore=NCORE)\n",
    "#     os.system('sleep 5;')\n",
    "    return \n",
    "\n",
    "def cmd_combineFastq(fnames,run=0):\n",
    "    fnames = list(fnames)\n",
    "    d = PTN.match(fnames[0]).groupdict()\n",
    "    cmd = 'cat {IN} >{lead}_R{read}_raw.{ext} ; rm {IN} '.format(IN=' '.join(fnames),\n",
    "                                                 **d)\n",
    "    return cmd\n",
    "def cmd_ungzip(F,):\n",
    "    cmd = 'gzip -d <{IN} >{OUT} ; rm {IN} '.format(IN=F,OUT=F.rstrip('.gz'))\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'test'\n",
    "pwd = os.getcwd()\n",
    "try:\n",
    "    os.chdir('test')\n",
    "    path = '/home/feng/syno3/PW_HiSeq_data/testData/'\n",
    "    res = process_rna_sample(path,debug=1)\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    os.chdir(pwd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
