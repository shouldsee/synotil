{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provisional title:\n",
    "\n",
    "Modelling co-regulated genes with Exponentiated Gaussian Mixtures: A case study on RNA-Seq data from a model-grass species.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| symbol  |  quantity  |  |  |\n",
    "| ------  | ---------- | - | - |\n",
    "|  $A$      | coverage   |  |  |\n",
    "| $()_g$| gene index |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Whole genome bulk RNA sequencing has become arguably one of the most important application of the ever-increasing sequencing capacity, provided by NextGen technologies. RNASeq allows for simultaneous quantification of tens of thousands of transcripts at 10x-100x coverage (defined as number of aligned reads per base pair of transcriptome), depending on the sequencing kit. Modern alignment pipelines seek to align the short reads back to the transcriptome in a spliced fashion, calculating a single scalar (coverage) for each transcript to quantify its abuandance. This effectively specifies transcriptome as a high-dimensional vector,the coverage vector $A_g$, where $g$ indexes gene by assuming a one-to-one mapping from transcripts to genes. Although transcript abuandance does not necessary reflects protein abundance due to possible post-transcriptional regulation, the rapid availability and relative stability of bulk RNA-Seq renders it a great, if not perfect, proxy for bridging statistical inference to biological hypotheses.\n",
    "\n",
    "Since absolute quantification of transcript level proved to be difficult, many normalisation schemes have been proposed as remedies, including RPKM (reads-per-kilobase-million-reads ), CPM (counts-per-million) and TPM (transcripts-per-million). We will be using TPM here for its nice property of summing up to $10^6$ over each sample @TPM. Denoting $T_{gc}$ as TPM for gene $g$ under condition $c$, we have $\\sum_g T_{gc}=10^6$.\n",
    "\n",
    "The purpose of this study will be to try modelling $T_{gc}$, by borrowing a powerful tool from the machine learning community known as Gaussian Mixture Model (GMM,@GMM-MLAPP,@GMM-sklearn), the probabilistic extension of K-means clustering algorithm @K-means. This application relies on $T_{gc}$ containing an intrinsic structure that allows it to be compressed into a latent reperesentation $z_g$ @Tradict. Specifically, I assumes $T_{gc}$, after appropriate normalisation, can be projected to a low-dimensional representation $( z_g, (\\mu_z,\\Sigma_z) )$ with approximately $|{z}|<50$. Importantly, during the normalisation step, I make the additional assumption that the average abundance over condition is not important in validating most of the biological hypotheses, $\\text{Avg}(T_g) = \\sqrt[C]{\\prod_c{T_{gc}}}$ (The exact numerical treatment will be discussed later in \\ref{sec:result}. ). \n",
    "\n",
    "The assumption above is based on that most biologically revelant hypotheses are centered around the response of gene expression (hence transcript abundance) to a condition change $c_1\\rightarrow c_2$ (===PPE===).  In particular, inference of a multiplicative response, or fold-change, has been studied extensively, with numerous biology-inspired heuristics proposed to improve the reliability of the inference @edgeR,DESeq2. Therefore, I will try to compare GMM-based approach\n",
    "\n",
    "Algorithm-wise, I will use a variational implementation of dirichlet process gaussian mixture model (DPGMM)l provided by the well known python package for machine learning: scikit-learn @sklearn, to infer the latent representation $\\mathcal{M} = (z_g,(\\mu_z,\\Sigma_z))$. Notably, DPGMM assumes a dirchelet process as its prior for the latent label $z_g$, hence enforcing the compression by to preferring a compressive map $z_g=Z(g)$ that is invertible and information-reducing. The full statistical model may be found in \\ref{sec:method}. \n",
    "\n",
    "In order to simplify the analysis, I will only use annotated transcripts in this study and restrain from inferring de-novo transcripts since they require further validation beyond the scope of this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material and Method\n",
    "\n",
    "## Source of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Pseudo-count log-transformation\n",
    "\n",
    "Compression again\n",
    "\n",
    "## Removing the biologically-irrelevant intercept (BII) $E(\\log T)$ \n",
    "\n",
    "## Inferrence of the latent labeling $z_g$\n",
    "\n",
    "## Merging similar labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 17 21:53:22 BST 2018\r\n"
     ]
    }
   ],
   "source": [
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username for 'https://github.com': ^C\n"
     ]
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31m.ipynb_checkpoints/00_intro-checkpoint.ipynb\u001b[m\r\n",
      "\t\u001b[31m00_intro.ipynb\u001b[m\r\n",
      "\r\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\r\n"
     ]
    }
   ],
   "source": [
    "! git add 00_intro.ipynb; git commit -m [add]Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Outline:\n",
    "\n",
    "* Justification of the usage of log2p1 using QC plots and histograms, to show the distribution is more Gaussian after this transformation.\n",
    "\n",
    "* Justifying the meanNorm. The simplest argument is that if meanNorm is not applied, the genes will cluster by their average expression. \n",
    "\n",
    "  - Genes may share a variation profile $\\lambda_g(j)$ but differ in average expression $\\mu_g$\n",
    "  \n",
    "* Note the constraining of GMM to a diagonal covariance matrix and illustrate the difference between full covar and diag covar. Model $\\lambda_g(j)\\sim \\mathcal{N}(\\nu,\\Sigma)$, we are only interesting in $\\nu$ and $\\Sigma$ needs to be **diagonal**, which means we ignore any correlated deviation from $\\nu$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
