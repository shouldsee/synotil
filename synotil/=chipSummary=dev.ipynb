{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ln \\=chipSummary\\=dev.ipynb /home/feng/repos/BrachyPhoton/synotil/ -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "envPull; \n",
    "chipSummary.py $INPUT  --ref Bdistachyon_314_v3.1.gene_exons.gtf.cds \\\n",
    "  --FC 1.5 --PVALUE 0.1 --QVALUE 0.1 -v \\\n",
    "  -o 188C-RESEQ_chipSum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.config\n",
    "%%FC=1.5 QVALUE=0.0005 PVALUE=0.01\n",
    "%%PAIRWISE_COMPARE=Y\n",
    "%%TITLE=testRun\n",
    "@test_1percent\n",
    "CHIP:/home/feng/temp/test/test_1per.bam\n",
    "INPUT:/home/feng/temp/test/test_1per.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipy = get_ipython()\n",
    "# ipy.register_magics?\n",
    "# ipy.\n",
    "# %env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditions_d['condition']\n",
    "# condit\n",
    "# %magic env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /home/feng/repos/BrachyPhoton/pipeline_rnaseq/chipSummary.py\n",
    "#!/usr/bin/env python\n",
    "# Usage: python chip-summary.py summary.txt\n",
    "#\n",
    "# Purpose: find target genes for many ChIP-seq samples.\n",
    "#\n",
    "# Note: summary.txt specifies BAM files. See QUICKSTART.txt to get started.\n",
    "#\n",
    "# Last modified 10 Oct 2016, slcu, hui lan\n",
    "# Last modified 14 July 2017, slcu, hui\n",
    "# Jun 2018, Feng: Refactored to take *.bed as input.\n",
    "\n",
    "import os, sys, subprocess, operator, glob, shutil\n",
    "import pymisca.util as pyutil\n",
    "\n",
    "\n",
    "def delete_file(fname):\n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "\n",
    "def delete_files(s):\n",
    "    for file in glob.glob(s):\n",
    "        delete_file(file)\n",
    "\n",
    "\n",
    "def move_files(s, dst):\n",
    "    for file in glob.glob(s):\n",
    "        if not os.path.exists(dst.rstrip('/') + '/' + file):\n",
    "            shutil.move(file, dst)\n",
    "        else:\n",
    "            os.remove(file)\n",
    "\n",
    "def calc_npeak(lst, fname, pvalue, qvalue):\n",
    "\n",
    "    n = []\n",
    "\n",
    "    for x in lst:\n",
    "        # print('...calculate number of peaks for various thresholds')\n",
    "        parameter_string = 'fc=%g p=%g q=%g' % (x, pvalue, qvalue)        \n",
    "        temp_small_narrowPeak = 'temp_small.narrowPeak'\n",
    "#         df = pd.read_table(fname)\n",
    "#         df.query()\n",
    "        cmd = 'python ' + PEAK_SELECT_SCRIPT + ' ' + fname + ' ' + parameter_string + ' > ' + temp_small_narrowPeak\n",
    "        # print(cmd)\n",
    "        os.system(cmd)\n",
    "        with open(temp_small_narrowPeak) as f:\n",
    "            n.append(len(f.readlines()))\n",
    "\n",
    "    return n\n",
    "        \n",
    "def plot_npeak_vs_fc(lstx, lsty, fname):\n",
    "\n",
    "    n = len(lstx)\n",
    "    max_npeak = max(lsty)\n",
    "    interval = max(1,max_npeak) / 120.0\n",
    "    f = open(fname, 'w')\n",
    "    f.write('Fold-change (fc) versus Number of Peaks plot\\n\\n')\n",
    "    for i in range(n):\n",
    "        f.write('fc=%3.1f |' % (lstx[i]))\n",
    "        npeaks = lsty[i]\n",
    "        f.write('|'*int(1.0*npeaks/interval))\n",
    "        f.write(' %d\\n' % npeaks)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def get_go(fname, type):\n",
    "\n",
    "    d = {}\n",
    "    f = open(fname)\n",
    "    for line in f:\n",
    "        if line.startswith('GO:'):\n",
    "            lst = line.split('\\t')\n",
    "            go_name = lst[0]\n",
    "            go_description = lst[3]\n",
    "            if lst[1] == type.upper():\n",
    "                d[go_name] = go_description\n",
    "    f.close()\n",
    "    return d\n",
    "\n",
    "\n",
    "def make_go_string(lst, d):\n",
    "\n",
    "    s = ''\n",
    "    for x in lst:\n",
    "        s += x + '\\t' + d[x] + '\\n'\n",
    "    return s\n",
    "\n",
    "\n",
    "def go_diff3(f1, f2, f3, type):\n",
    "\n",
    "    d1 = get_go(f1, type)\n",
    "    d2 = get_go(f2, type)\n",
    "    d3 = get_go(f3, type)\n",
    "    uniq1 = list(set(d1.keys()) - (set(d2.keys()) | set(d3.keys())))\n",
    "    uniq2 = list(set(d2.keys()) - (set(d1.keys()) | set(d3.keys())))\n",
    "    uniq3 = list(set(d3.keys()) - (set(d1.keys()) | set(d2.keys())))\n",
    "    s1 = make_go_string(uniq1, d1)\n",
    "    s2 = make_go_string(uniq2, d2)\n",
    "    s3 = make_go_string(uniq3, d3)\n",
    "    return [s1, s2, s3]\n",
    "\n",
    "def go_diff3_bpmfcc(f1, f2, f3):\n",
    "\n",
    "    bp = go_diff3(f1, f2, f3, 'bp')\n",
    "    mf = go_diff3(f1, f2, f3, 'mf')\n",
    "    cc = go_diff3(f1, f2, f3, 'cc')    \n",
    "\n",
    "    result = ['', '', '']\n",
    "    for i in range(len(bp)):\n",
    "        result[i] += 'BP:\\n' +  bp[i]\n",
    "\n",
    "    for i in range(len(mf)):\n",
    "        result[i] += '\\n'\n",
    "        result[i] += 'MF:\\n' +  mf[i]        \n",
    "\n",
    "    for i in range(len(cc)):\n",
    "        result[i] += '\\n'\n",
    "        result[i] += 'CC:\\n' +  cc[i]        \n",
    "\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def make_pairwise_comparison_html_page(c1, c2, d, dir_name, agi2genename_dict):\n",
    "\n",
    "    d1 = d[c1]\n",
    "    d2 = d[c2]\n",
    "    html_page = dir_name.rstrip('/') + '/' + c1 + '_vs_' + c2 + '.html'\n",
    "    text_file1 = c1 + '_vs_' + c2 + '_1.txt'\n",
    "    text_file2 = c1 + '_vs_' + c2 + '_2.txt'\n",
    "    text_file3 = c1 + '_vs_' + c2 + '_3.txt'    \n",
    "\n",
    "    fname1 = c1 + '_vs_' + c2 + '_1_GOenrichment.txt'\n",
    "    fname2 = c1 + '_vs_' + c2 + '_2_GOenrichment.txt'\n",
    "    fname3 = c1 + '_vs_' + c2 + '_3_GOenrichment.txt'\n",
    "\n",
    "    ufname1 = os.path.splitext(fname1)[0] + '_uniq.txt'\n",
    "    ufname2 = os.path.splitext(fname2)[0] + '_uniq.txt'\n",
    "    ufname3 = os.path.splitext(fname3)[0] + '_uniq.txt'\n",
    "\n",
    "    d1minusd2 = sorted(list(set(d1.keys()) - set(d2.keys())))\n",
    "    d2minusd1 = sorted(list(set(d2.keys()) - set(d1.keys())))\n",
    "    d1intd2 = sorted(list(set(d1.keys()).intersection(d2.keys())))\n",
    "    sz_d1minusd2 = len(d1minusd2)\n",
    "    sz_d2minusd1 = len(d2minusd1)\n",
    "    sz_d1intd2 = len(d1intd2)\n",
    "    f = open(html_page, 'w')\n",
    "    f1 = open(text_file1,'w')\n",
    "    f2 = open(text_file2,'w')\n",
    "    f3 = open(text_file3,'w')\n",
    "    f.write('<html>')\n",
    "    f.write('<head>')\n",
    "    f.write('<style> body {font-family:\\\"HelveticaNeue-Light\\\", \\\"Helvetica Neue Light\\\", \\\"Helvetica neue\\\"} </style>')\n",
    "    f.write('</head>')\n",
    "    f.write('<body>')\n",
    "    f.write('<p>Condition A: %s</p>' % (c1))\n",
    "    f.write('<p>Condition B: %s</p>' % (c2))    \n",
    "    f.write('<p>First column: all genes in condition A but not in condition B; second column: all genes in both conditions; third column: all genes in condition B but not in condition A.</p>')\n",
    "    f.write('<table border=1>')\n",
    "    f.write('<tr>')\n",
    "    f.write('<td>%s <br/><i>SUBTRACT</i><br/> %s <br/>(number=%d) <br/><a href=\\\"%s\\\">Download</a><br/><a href=\\\"%s\\\">GO enrichment</a><br/><a href=\\\"%s\\\">Unqiue GO enrichment</a></td> <td>%s <br/><i>AND</i><br/> %s <br/>(number=%d) <br/><a href=\\\"%s\\\">Download</a> <br/><a href=\\\"%s\\\">GO enrichment</a><br/><a href=\\\"%s\\\">Unique GO enrichment</a></td> <td>%s <br/><i>SUBTRACT</i></br> %s <br/>(number=%d) <br/><a href=\\\"%s\\\">Download</a><br/><a href=\\\"%s\\\">GO enrichment</a><br/><a href=\\\"%s\\\">Unique GO enrichment</a></td>' % (c1,c2,sz_d1minusd2,text_file1,fname1,ufname1,c1,c2,sz_d1intd2,text_file2,fname2,ufname2,c2,c1,sz_d2minusd1,text_file3,fname3,ufname3))\n",
    "    f.write('</tr>')\n",
    "    for i in range(max(sz_d1minusd2, sz_d1intd2, sz_d2minusd1)):\n",
    "        f.write('<tr>')\n",
    "        if i < sz_d1minusd2:\n",
    "            x = d1minusd2[i]\n",
    "            if (x in agi2genename_dict) and (agi2genename_dict[x] != x):\n",
    "                f.write('<td>%s (%s)</td>' % (x, agi2genename_dict[x]))\n",
    "            else:\n",
    "                f.write('<td>%s</td>' % (x))\n",
    "            f1.write('%s\\n' % (x))\n",
    "        else:\n",
    "            f.write('<td>-</td>')\n",
    "        if i < sz_d1intd2:\n",
    "            x = d1intd2[i]\n",
    "            if (x in agi2genename_dict) and (agi2genename_dict[x] != x):\n",
    "                f.write('<td>%s (%s)</td>' % (x, agi2genename_dict[x]))\n",
    "            else:\n",
    "                f.write('<td>%s</td>' % (x))\n",
    "            f2.write('%s\\n' % (x))                \n",
    "        else:\n",
    "            f.write('<td>-</td>')\n",
    "        if i < sz_d2minusd1:\n",
    "            x = d2minusd1[i]\n",
    "            if (x in agi2genename_dict) and (agi2genename_dict[x] != x):\n",
    "                f.write('<td>%s (%s)</td>' % (x, agi2genename_dict[x]))\n",
    "            else:\n",
    "                f.write('<td>%s</td>' % (x))\n",
    "            f3.write('%s\\n' % (x))                \n",
    "        else:\n",
    "            f.write('<td>-</td>')            \n",
    "        f.write('<tr>')\n",
    "    f.write('</table>')    \n",
    "    f.write('</body>')\n",
    "    f.write('</html>')    \n",
    "    f.close()\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f3.close()\n",
    "\n",
    "    \n",
    "    cmd = 'bash ' + GO_ENRICHMENT_SCRIPT + ' ' + text_file1 + ' > ' + fname1\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'bash ' + GO_ENRICHMENT_SCRIPT + ' ' + text_file2 + ' > ' + fname2\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'bash ' + GO_ENRICHMENT_SCRIPT + ' ' + text_file3 + ' > ' + fname3\n",
    "    print(cmd)\n",
    "    os.system(cmd)    \n",
    "\n",
    "    diff_lst = go_diff3_bpmfcc(fname1, fname2, fname3)\n",
    "    with open(ufname1, 'w') as text_file:\n",
    "        text_file.write(diff_lst[0])\n",
    "    with open(ufname2, 'w') as text_file:\n",
    "        text_file.write(diff_lst[1])\n",
    "    with open(ufname3, 'w') as text_file:\n",
    "        text_file.write(diff_lst[2])\n",
    "    \n",
    "    cmd = ' '.join(['mv', text_file1, text_file2, text_file3, fname1, fname2, fname3, ufname1, ufname2, ufname3, dir_name])\n",
    "    os.system(cmd)\n",
    "    return [sz_d1minusd2, sz_d2minusd1, sz_d1intd2, html_page]\n",
    "    \n",
    "    \n",
    "def make_comparison_table(f, gene_lists, agi2genename_dict, dir_name):\n",
    "    conditions = sorted(gene_lists.keys())\n",
    "    size = len(conditions)\n",
    "    f.write('<table border=1>')\n",
    "    f.write('<tr>')\n",
    "    f.write('<td>-</td>')\n",
    "    for i in range(1,size):\n",
    "        f.write('<td>%s</td>' % (conditions[i]))\n",
    "    f.write('</tr>')\n",
    "    for i in range(size-1):\n",
    "        c1 = conditions[i]\n",
    "        f.write('<tr>')\n",
    "        f.write('<td>%s</td>' % (c1))\n",
    "        for j in range(1,size):\n",
    "            if i >= j:\n",
    "                f.write('<td>-</td>')\n",
    "            else:\n",
    "                c2 = conditions[j]\n",
    "                t = make_pairwise_comparison_html_page(c1, c2, gene_lists, dir_name, agi2genename_dict)\n",
    "                f.write('<td><a href=\\\"%s\\\">%d,%d,%d</a></td>' % (t[3], t[0], t[2], t[1]))\n",
    "        f.write('</tr>')\n",
    "    f.write('</table>')            \n",
    "    \n",
    "    \n",
    "def make_gene_list_dict(s):\n",
    "    lst = s.split('\\n')\n",
    "    d = {}\n",
    "    for x in lst:\n",
    "        t = x.split()\n",
    "        if len(t) > 1 and t[0] != 'AGI_code':\n",
    "            gene = t[0]\n",
    "            if not gene in d:\n",
    "                d[gene] = t[1]\n",
    "    return d\n",
    "\n",
    "\n",
    "def make_goenrichment_file(name, d):\n",
    "\n",
    "    f = open('temp_gene_list.txt', 'w')\n",
    "    gene_names = d.keys()\n",
    "    f.write('\\n'.join(gene_names))\n",
    "    f.close()\n",
    "    fname = name + '_GOenrichment.txt'\n",
    "    cmd = 'bash ' + GO_ENRICHMENT_SCRIPT + ' temp_gene_list.txt > ' + fname\n",
    "    os.system(cmd)\n",
    "    return fname\n",
    "\n",
    "\n",
    "def make_goenrichment_diff(lst, dir_name):\n",
    "\n",
    "    cmd = 'python ' + GO_ENRICHMENT_DIFF_SCRIPT\n",
    "    filename = dir_name.rstrip('/') + '/enrich_diff.txt'\n",
    "    for x in lst:\n",
    "        cmd += ' ' + x\n",
    "    cmd += ' > ' + filename\n",
    "    os.system(cmd)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def make_text_gene_list(name, d0, d):\n",
    "    '''\n",
    "    name - intended file name\n",
    "    d0 - dictionary where key is gene id, and value is fold-change\n",
    "    d  - gene id to gene name conversion, e.g., AT3G14180 to IGN\n",
    "    '''\n",
    "    \n",
    "    fname = name + '_gene_list.txt'\n",
    "    f = open(fname, 'w')\n",
    "    f.write('\\t'.join(['AGI_code', 'max_fold_change_in_nearby_peaks', 'gene_name']))\n",
    "    f.write('\\n')\n",
    "    for x in sorted(d0.keys()):\n",
    "        v = d0[x]\n",
    "        if (x in d) and (d[x] != x): # has a gene name, show gene name\n",
    "            f.write('%s\\t%s\\t%s\\n' % (x, v, d[x]))\n",
    "        else:\n",
    "            f.write('%s\\t%s\\n' % (x, v))\n",
    "    f.close()\n",
    "    return fname\n",
    "\n",
    "\n",
    "def make_AGI_to_gene_name_dict(fname):\n",
    "    d = {}\n",
    "    f = open(fname)\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        lst = line.split()\n",
    "        agi = lst[0]\n",
    "        name = lst[1]\n",
    "        if not agi in d:\n",
    "            d[agi] = name\n",
    "        else:\n",
    "            d[agi] += d[agi] + ';' + name\n",
    "    f.close()\n",
    "    return d\n",
    "\n",
    "def get_parameter_value_float(s):\n",
    "    index = s.find('=')\n",
    "    result = 0.0\n",
    "    try:\n",
    "        result = float(s[index+1:])\n",
    "    except:\n",
    "        result = 1.0 * int(s[index+1:])\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_parameter_value_string(s):\n",
    "    return s[s.find('=') + 1:].strip()\n",
    "\n",
    "def get_parameter_value_int(s):\n",
    "    return int(get_parameter_value_string(s))\n",
    "    \n",
    "def get_global_parameters(fname):\n",
    "    d = {'FC':2.0, 'QVALUE':0.01, 'PVALUE':0.05, 'PAIRWISE_COMPARE':'NO', 'TITLE':'None', 'TARGET_RANGE':DEFAULT_TARGET_RANGE}\n",
    "    f = open(fname)\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.startswith('%%'):\n",
    "            l = line[2:]\n",
    "            lst = l.split()\n",
    "            for x in lst:\n",
    "                if x.upper().startswith('FC='):\n",
    "                    d['FC'] = get_parameter_value_float(x)\n",
    "                if x.upper().startswith('QVALUE='):\n",
    "                    d['QVALUE'] = get_parameter_value_float(x)\n",
    "                if x.upper().startswith('PVALUE='):\n",
    "                    d['PVALUE'] = get_parameter_value_float(x)\n",
    "                if x.upper().startswith('PATH'):\n",
    "                    key = x[0:x.find('=')]\n",
    "                    d[key] = get_parameter_value_string(x)\n",
    "                if x.upper().startswith('PAIRWISE_COMPARE'):\n",
    "                    d['PAIRWISE_COMPARE'] = get_parameter_value_string(x)\n",
    "                if x.upper().startswith('TITLE'):\n",
    "                    d['TITLE'] = get_parameter_value_string(x)\n",
    "                if x.upper().startswith('TARGET_RANGE'):\n",
    "                    d['TARGET_RANGE'] = get_parameter_value_string(x)\n",
    "    f.close()\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_local_parameter(s):\n",
    "\n",
    "    d = {}\n",
    "    t = s[1:]\n",
    "    t = t.strip()\n",
    "    lst = t.split()\n",
    "    for x in lst:\n",
    "        if x.upper().startswith('FC='):\n",
    "            d['FC'] = get_parameter_value_float(x)\n",
    "        if x.upper().startswith('QVALUE='):\n",
    "            d['QVALUE'] = get_parameter_value_float(x)\n",
    "        if x.upper().startswith('PVALUE='):\n",
    "            d['PVALUE'] = get_parameter_value_float(x)\n",
    "\n",
    "    return d\n",
    "    \n",
    "def get_path(s, glb_dict):\n",
    "    '''\n",
    "    expand PATH macro with real path\n",
    "    '''\n",
    "    index = s.find(':')\n",
    "    t = s[index+1:]\n",
    "    result = ''\n",
    "    lst = t.split()\n",
    "    for x in lst:\n",
    "        a = x.find('<')\n",
    "        b = x.find('>')\n",
    "        if b > a and a >= 0:\n",
    "            key = x[a+1:b]\n",
    "            result += glb_dict[key]\n",
    "            result += x[b+1:]\n",
    "        else:\n",
    "            result += x\n",
    "    res = glob.glob(result)\n",
    "    print res\n",
    "    assert res,'[glob] empty glob:\"%s\"'%result\n",
    "    assert len(res)==1,'[glob] ambiguous: %s'%('\\n'.join(res))\n",
    "    return res[0]\n",
    "\n",
    "\n",
    "def get_conditions(fname, glb_dict):\n",
    "    '''\n",
    "    get all ChIPs/INPUT in different conditions\n",
    "    '''\n",
    "\n",
    "    d = {} # will be {cond1:{'CHIP':'...', 'INPUT':'...'}, cond2 :{}}\n",
    "    f = open(fname)\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.startswith('@'):\n",
    "            key = line[1:]\n",
    "            key = key.replace(' ', '-')  # replace all spaces with a dash\n",
    "            if not key in d:\n",
    "                d[key] = {}\n",
    "                \n",
    "        if line.upper().startswith('CHIP:'):\n",
    "            d[key]['CHIP'] = get_path(line, glb_dict)\n",
    "        if line.upper().startswith('INPUT:'):\n",
    "            d[key]['INPUT'] = get_path(line, glb_dict)\n",
    "        if line.upper().startswith('%') and not line.upper().startswith('%%'):\n",
    "            d[key]['PEAK_SELECT_PARAM'] = get_local_parameter(line)\n",
    "\n",
    "    f.close()\n",
    "    return d\n",
    "\n",
    "\n",
    "def dumpclean(obj):\n",
    "    '''\n",
    "    show dictionary content, recursively\n",
    "    '''\n",
    "    if type(obj) == dict:\n",
    "        for k, v in obj.items():\n",
    "            if hasattr(v, '__iter__'):\n",
    "                print k\n",
    "                dumpclean(v)\n",
    "            else:\n",
    "                print '%s : %s' % (k, v)\n",
    "    elif type(obj) == list:\n",
    "        for v in obj:\n",
    "            if hasattr(v, '__iter__'):\n",
    "                dumpclean(v)\n",
    "            else:\n",
    "                print v\n",
    "        else:\n",
    "            print obj\n",
    "\n",
    "\n",
    "def make_peak_call_script(key, dict, template_file):\n",
    "\n",
    "    d = dict[key]\n",
    "    outfilename = 'pipeline_' + key + '.sh'\n",
    "    f = open(outfilename, 'w')\n",
    "    f.write('# bam file paths\\n')\n",
    "    f.write('name=\\\"%s\\\"\\n' % (key.strip()))\n",
    "    for k in d:\n",
    "        if k.startswith('CHIP'):\n",
    "            f.write('chip=\\\"%s\\\"\\n' % (d[k].strip()))\n",
    "        if k.startswith('INPUT'):\n",
    "            f.write('input=\\\"%s\\\"\\n' % (d[k].strip()))\n",
    "            \n",
    "    f.write('\\n')\n",
    "    with open(template_file) as infile:\n",
    "        f.write(infile.read())\n",
    "    f.close()\n",
    "    return outfilename\n",
    "\n",
    "def make_param_string(d):\n",
    "    result = ''\n",
    "    for k in d:\n",
    "        if k == 'FC':\n",
    "            result += 'fc=' + str(d[k]) + ' '\n",
    "        if k == 'QVALUE':\n",
    "            result += 'q=' + str(d[k]) + ' '\n",
    "        if k == 'PVALUE':\n",
    "            result += 'p=' + str(d[k]) + ' '\n",
    "    return result.strip()\n",
    "\n",
    "\n",
    "def peak_to_target_genes(peak_file, bedmap_range,dbg=0):\n",
    "\n",
    "    cmd = 'bedmap --echo --echo-map-id-uniq --delim \\'\\t\\' ' \\\n",
    "          + '--range ' + bedmap_range \\\n",
    "          + ' ' + peak_file \\\n",
    "          + ' ' + ANNOTATION_FILE + ' > a.txt'\n",
    "    if dbg: \n",
    "        print cmd\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'cut -f 11 a.txt > a2.txt'\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'python ' + GENELOCUS_TO_GENENAME_SCRIPT + ' a2.txt ' +  GENE_DESCRIPTION + ' > b.txt'\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'paste a.txt b.txt > c.txt'\n",
    "    os.system(cmd)\n",
    "\n",
    "    # delete a line in c.txt if that lines contains transposable_element_gene or Not Found\n",
    "    cmd = 'sed \\'/transposable_element_gene\\|Not Found/d\\' c.txt > d.txt'\n",
    "    os.system(cmd)\n",
    "    \n",
    "    cmd = 'python ' + EXTRACT_AGI_CODE_AND_FC + ' d.txt'\n",
    "    print cmd\n",
    "    res = subprocess.check_output(cmd,shell=1)\n",
    "    return res\n",
    "#     subprocess.callos.system(cmd)\n",
    "\n",
    "def program_installed(pname):\n",
    "    try:\n",
    "        subprocess.call([pname, \"--help\"], stdout=open(os.devnull, 'w'), stderr=subprocess.STDOUT)\n",
    "    except OSError as e:\n",
    "        if e.errno == os.errno.ENOENT:\n",
    "            print('ERROR: %s not found.' % (pname))\n",
    "        else:\n",
    "            print('ERROR: something is wrong with %s' % (pname))\n",
    "        sys.exit()\n",
    "\n",
    "def goatools_installed():\n",
    "    f = open(GO_ENRICHMENT_SCRIPT)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    line = lines[0].strip()\n",
    "    lst = line.split('=')\n",
    "    goatool_path = lst[1].strip()\n",
    "    if not os.path.exists(os.path.join(goatool_path, 'scripts/find_enrichment.py')):\n",
    "        print('ERROR: goatools not installed.  Install it and specify its path in the first line of chip-summary/depend/script/fe.sh')\n",
    "        sys.exit()\n",
    "    if not os.path.exists(os.path.join(goatool_path, 'scripts/go-basic.obo')):\n",
    "        print('ERROR: go-basic.obo does not exists.  Download it (http://geneontology.org/ontology/go-basic.obo) and put it in folder goatools/scripts/.')\n",
    "        sys.exit()\n",
    "        \n",
    "def main(f,dbg= 0,reCallPeak=0,gPar= None):\n",
    "    global shellexec\n",
    "    def shellexec(cmd,dbg= 0 ):\n",
    "        if dbg:\n",
    "            print cmd\n",
    "            res = 'dbg'\n",
    "        else:\n",
    "            res = subprocess.check_output(cmd,shell=1)\n",
    "        return res\n",
    "    \n",
    "#     #############################################################################################\n",
    "\n",
    "#     DEPENDENT_FILES_PATH        = '/media/pw_synology3/Software/chip-summary/'  # [path of chip-summary.py]\n",
    "#     DEFAULT_TARGET_RANGE        = '3000' # [change]  a string, not a number\n",
    "#     SUMMARY_FILE_NAME           = 'summary.html'\n",
    "#     SUMMARY_DIR                 = 'summary'\n",
    "#     PEAK_CALL_PIPELINE_TEMPLATE = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/pipeline724-t.sh')\n",
    "#     PEAK_SELECT_SCRIPT          = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/select_peaks.py')\n",
    "#     GENELOCUS_TO_GENENAME_SCRIPT= os.path.join(DEPENDENT_FILES_PATH, 'depend/script/genelocus2genename.py')\n",
    "    \n",
    "#     #### Slowest part to be refactored???\n",
    "#     EXTRACT_AGI_CODE_AND_FC     = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/extract_AGI_code_and_fold_change.py')\n",
    "#     GO_ENRICHMENT_SCRIPT        = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/fe.sh')  # install goatools (GO enrichment) and edit fe.sh\n",
    "#     GO_ENRICHMENT_DIFF_SCRIPT   = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/goterm-matrix.py')\n",
    "#     AGI_TO_GENE_NAMES           = os.path.join(DEPENDENT_FILES_PATH, 'depend/data/AGI-to-gene-names.txt')\n",
    "#     ANNOTATION_FILE             = os.path.join(DEPENDENT_FILES_PATH, 'depend/data/genesTAIR10.bed') # for bedmap\n",
    "#     GENE_DESCRIPTION            = os.path.join(DEPENDENT_FILES_PATH, 'depend/data/gene_description_20140101.txt')\n",
    "#     MAX_FOLD_CHANGE             = 10  # for number of peaks versus fold-change plot\n",
    "\n",
    "#     #############################################################################################\n",
    "    \n",
    "    gPar =  gPar or get_global_parameters(f)\n",
    "    condDict = get_conditions(f, gPar)\n",
    "    DIR = pyutil.dict2flat(gPar)\n",
    "#     os.system('mkdir -p ' + DIR); os.chdir(DIR)\n",
    "    if dbg == 1:\n",
    "        d = gPar,condDict\n",
    "        for dd in d:\n",
    "            print pyutil.ppJson(dd)\n",
    "\n",
    "        return d\n",
    "#     try:\n",
    "    if 1:\n",
    "\n",
    "        # Collect results\n",
    "        os.system('mkdir -p %s'%SUMMARY_DIR)\n",
    "\n",
    "\n",
    "        # make pipeline files for peak calling\n",
    "        def getPeak(k):\n",
    "            sname = make_peak_call_script(k, condDict, PEAK_CALL_PIPELINE_TEMPLATE)\n",
    "            print('Run %s ...' % (sname))        \n",
    "            res = subprocess.call(['bash', sname])\n",
    "#             return '%s_peaks.narrowPeak'%k\n",
    "            return res\n",
    "        \n",
    "        if reCallPeak:\n",
    "            # check that every ChIP file is present\n",
    "            for k in condDict.keys():\n",
    "                chip_file = condDict[k]['CHIP']\n",
    "                input_file = condDict[k]['INPUT']\n",
    "                if not os.path.exists(chip_file):\n",
    "                    print('%s dose not exist. STOP' % (chip_file))\n",
    "                    sys.exit()\n",
    "                if not os.path.exists(input_file):\n",
    "                    print('%s dose not exist. STOP' % (input_file))\n",
    "                    sys.exit()\n",
    "            [getPeak(k) for k in condDict.keys()]\n",
    "            \n",
    "        npkFS = ['%s_peaks.narrowPeak'%k for k in condDict.keys()]\n",
    "        peakSummary(npkFS)\n",
    "        \n",
    "        gene_lists = {} # a dictionary of form d  = {'condition1': {'AT1G12345':'2.3', 'AT1G12346':'1.2'} }\n",
    "        \n",
    "\n",
    "def process(k=None,npkFile=None,gPar= None,dbg = 0):\n",
    "    if k is None:\n",
    "        assert npkFile,'must specify one arg'\n",
    "        k = npkFile.rsplit('.',1)[0].split('/')[-1]\n",
    "        \n",
    "\n",
    "#             d = condDict[k]\n",
    "    outd = {'files':{}}\n",
    "\n",
    "    if 1:\n",
    "#         parameter_string = 'fc=1.5 q=0.001 p=0.01'\n",
    "        parameter_string = make_param_string(gPar)            \n",
    "\n",
    "#             fileMacs = '%s/peaks/%s_peaks.narrowPeak'%(SUMMARY_DIR,k)\n",
    "    small_narrowPeak = '{key}.snpk'.format(key=k)\n",
    "\n",
    "    ### PeakFiltering\n",
    "    cmd = 'python {SCRIPT} {INFILE} {PARAM} > {OUTF}'.format(\n",
    "        SCRIPT=  PEAK_SELECT_SCRIPT,\n",
    "        INFILE = npkFile,\n",
    "        PARAM= parameter_string,\n",
    "        OUTF = small_narrowPeak,\n",
    "    )\n",
    "    print(cmd);os.system(cmd)\n",
    "    outd['param'] = parameter_string\n",
    "\n",
    "#     cmd = 'cat {INFILE}  > {OUTF}'.format(\n",
    "# #         SCRIPT=  PEAK_SELECT_SCRIPT,\n",
    "#         INFILE = npkFile,\n",
    "# #         PARAM= parameter_string,\n",
    "#         OUTF = small_narrowPeak,\n",
    "#     )\n",
    "#     print(cmd);os.system(cmd)\n",
    "#     outd['param'] = parameter_string\n",
    "#     raise 0\n",
    "    #### Fancy Histogram\n",
    "    fc_thresholds = [x * 0.1 for x in range(10, 10*MAX_FOLD_CHANGE, 2)]\n",
    "    npeak_lst = calc_npeak(fc_thresholds, k + '_peaks.narrowPeak', gPar['PVALUE'], gPar['QVALUE'])            \n",
    "    plotName = SUMMARY_DIR.strip('/') + '/' + 'npeaks_vs_fc_' + k + '.txt' \n",
    "#     plot_npeak_vs_fc(fc_thresholds, npeak_lst, plotName)\n",
    "\n",
    "\n",
    "    #### Produce geneLists     \n",
    "    \n",
    "    file_bedmap =  '%s.bedmap.tsv'%k\n",
    "    \n",
    "    \n",
    "#     cmd = 'bedmap --echo --echo-map-id-uniq --delim \\'\\t\\' ' \\\n",
    "#       + '--range ' + gPar['TARGET_RANGE'] \\\n",
    "#       + ' ' + small_narrowPeak \\\n",
    "#       + ' ' + ANNOTATION_FILE + ' | tee ' + file_bedmap +'.tmp'\n",
    "    \n",
    "#     buf = StringIO.StringIO(pyutil.shellexec(cmd))\n",
    "# #     buf = file_bed\n",
    "# #     res_bedmap = pd.read_table(buf,header=None)\n",
    "    \n",
    "    \n",
    "# #     if buf.read():\n",
    "#     if buf.len:\n",
    "#         buf.seek(0)\n",
    "#         df = sutil.parseBedmap(fname = buf)\n",
    "#     else:\n",
    "#         header = sutil.bedHeader + ['hit']\n",
    "#         df = pd.DataFrame(columns = header)\n",
    "    \n",
    "    \n",
    "    cmd = '''\n",
    "bedtools slop -b {RANGE} -i {ANNO} -g $GSIZE |bedtools sort > {ANNOBASE}.{RANGE}\n",
    "bedtools closest -d -a {SNPK} -b {ANNOBASE}.{RANGE} | tee {FOUT}.tmp\n",
    "'''.format(\n",
    "        ANNO = ANNOTATION_FILE,\n",
    "        ANNOBASE=ANNOTATION_FILE.split('/')[-1],\n",
    "        SNPK = small_narrowPeak,\n",
    "        RANGE=gPar['TARGET_RANGE'],\n",
    "        FOUT = file_bedmap    \n",
    "    ).strip()\n",
    "    \n",
    "    buf = StringIO.StringIO(pyutil.shellexec(cmd))\n",
    "    if buf.len:\n",
    "        buf.seek(0)\n",
    "        df = sutil.parseBedClosest(fname = buf)\n",
    "    else:\n",
    "        assert 0,' Buffer is empty, check error msg'\n",
    "    df['condition'] = k\n",
    "    df = df[df['distance']==0]\n",
    "    \n",
    "#         raise e\n",
    "    df = df.sort_values('FC',ascending = False,inplace = 0)\n",
    "    \n",
    "    #### deduplication on gene acc\n",
    "    df = df.loc[~df.duplicated('hit')]\n",
    "    res_bedmap = df\n",
    "    df.to_csv(file_bedmap,sep='\\t')\n",
    "    \n",
    "    \n",
    "    genes = df\n",
    "    \n",
    "    outd['genes'] = None\n",
    "    outd['nGene'] = len(df['hit'].unique())\n",
    "    outd['file_bedmap'] = file_bedmap\n",
    "#     outd['res_bedmap'] = res_bedmap\n",
    "\n",
    "    fname = '%s/%s.gene.txt'% (SUMMARY_DIR,k)\n",
    "    dfc = df.copy()[['hit','FC', 'acc',]]\n",
    "    dfc.columns = ['geneAcc','maxFoldChange','peakAcc']\n",
    "    dfc.to_csv(fname,sep= '\\t')   \n",
    "    \n",
    "    \n",
    "    outd['glst_filename'] =  fname\n",
    "#     outd['goenrich_filename'] =  make_goenrichment_file(SUMMARY_DIR + '/' + k, genes)\n",
    "    outd['goenrich_filename'] =  'NotImplemented'\n",
    "    outd['plot_file'] = plotName \n",
    "    outd['peak_file'] = small_narrowPeak\n",
    "\n",
    "    outd['key'] = k\n",
    "    outd['extra'] = ''\n",
    "    return outd             \n",
    "\n",
    "def peakSummary(npkFS,gPar = None,dbg=0,\n",
    "               FC    = 1.5,\n",
    "               PVALUE=0.01,\n",
    "               QVALUE=0.0005,\n",
    "                **kwargs\n",
    "               ):\n",
    "    gPar = gPar or {\n",
    "    \"FC\": FC, \n",
    "    \"PVALUE\": PVALUE, \n",
    "    \"QVALUE\": QVALUE, \n",
    "    \"PAIRWISE_COMPARE\": \"Y\", \n",
    "    \"TARGET_RANGE\": \"3000\", \n",
    "    \"TITLE\": \"testRun\"\n",
    "}\n",
    "    \n",
    "#     f = functools.partial(process,gPar = gPar)\n",
    "    f = lambda x: process(npkFile = x,gPar = gPar,dbg = dbg)\n",
    "    condRes = res = map(f, npkFS)\n",
    "    if dbg:\n",
    "        with open('condRes.dbg','w') as f:\n",
    "            print >>f,pyutil.ppJson(condRes)\n",
    "    if dbg == 2:\n",
    "        return condRes\n",
    "    \n",
    "    \n",
    "    dfs = [pd.read_table(x['file_bedmap']).set_index('hit') for x in res]\n",
    "#     for df in dfs:\n",
    "#         print df.head(10)\n",
    "#     print [type(df) for df in dfs]\n",
    "    indAll = pd.concat( dfs,axis =1 ,join='outer').index\n",
    "    print '[db1]',dfs[0].head()\n",
    "\n",
    "    \n",
    "    df = pd.concat( [ df.reindex( indAll) for df in dfs],\n",
    "                   axis = 0) \n",
    "    df = df.reset_index()\n",
    "#     df..reset_index()\n",
    "#     df = df.set_index('hit')\n",
    "    \n",
    "    print '[db2]',df.head()\n",
    "\n",
    "    cols = df.columns.to_series()\n",
    "    cols[0]='index'\n",
    "    df.columns = cols\n",
    "    print '[db3]',df.head()\n",
    "    df_fc = df.pivot_table(columns = 'condition', values='FC',index='index').fillna(0)\n",
    "\n",
    "    sanitise = lambda x: x.split('.',1)[0]\n",
    "    df_fc.index = map(sanitise, df_fc.index)\n",
    "\n",
    "#     index = scount.vstack([dfs],as_index=1,how = 'outer')\n",
    "    getPM =    lambda lst: ''.join(['+' if x!=0 else '-' for x in lst])\n",
    "    vals = df_fc.apply(getPM,axis=1)\n",
    "    df_fc.insert(0,'pmSummary',vals)\n",
    "    print df_fc.head(10)\n",
    "    df_fc.to_csv('FoldChange_table.csv')\n",
    "\n",
    "    ##### write html summary report \n",
    "\n",
    "    print('... make html page %s' % (SUMMARY_FILE_NAME))\n",
    "\n",
    "    f = open(SUMMARY_FILE_NAME, 'w')\n",
    "    TITLE = 'test'\n",
    "#     TITLE = gPar['TITLE']\n",
    "    f.write('<html>')\n",
    "    f.write('<head>')\n",
    "    f.write('<title>%s</title>'% (TITLE) )\n",
    "    f.write('<style> body {font-family:\\\"HelveticaNeue-Light\\\", \\\"Helvetica Neue Light\\\", \\\"Helvetica neue\\\"} </style>')\n",
    "    f.write('</head>')\n",
    "    f.write('<body>')\n",
    "    f.write('<h2>%s</h2>' % (TITLE))\n",
    "\n",
    "    #####################################################################\n",
    "    f.write('<h3>Target genes and associated GO terms</h3>')\n",
    "\n",
    "    table_string = '<table><tr><td>Sample</td><td>Target gene list</td><td>#target genes</td><td>GO enrichment</td><td>Peak selection thresholds</td><td>#peaks plot</td></tr>'\n",
    "    rowFmt = '''\n",
    "        <tr><td>{key}</td>\n",
    "        <td><a href=\"{glst_filename}\">target genes</a></td>\n",
    "        <td align=right>{nGene:d}</td>\n",
    "        <td><a href=\"{goenrich_filename}\">enrichment</a></td>\n",
    "        <td><a href=\"{peak_file}\">{param}</a></td>\n",
    "        <td><a href=\"{plot_file}\">plot</a></td></tr>\n",
    "        '''\n",
    "    for d in res:\n",
    "        table_string += rowFmt.format(**d)\n",
    "\n",
    "\n",
    "\n",
    "    table_string += '</table>'\n",
    "    f.write(table_string)\n",
    "\n",
    "    #####################################################################\n",
    "    f.write('<h3>Enriched GO terms associated to target genes in different conditions</h3>')\n",
    "    f.write('<p>Most shared GO terms across conditions are on the top in the following table.</p>')\n",
    "    filename = make_goenrichment_diff([d['goenrich_filename'] for d in res],\n",
    "                                      SUMMARY_DIR)\n",
    "    f.write('<a href=\\\"%s\\\">Each row is a GO term. Each column is a condition.</a>' % (filename))\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "#     if gPar['PAIRWISE_COMPARE'].lower().startswith('y'): \n",
    "#         f.write('<h3>Pairwise comparison between conditions</h3>')\n",
    "#         f.write('<p>Each cell in the following table contains three numbers, X, Y and Z. X is the number of target genes that are in condition A but not in condition B. Z is the number of target genes that are in condition B but not in condition A.  Y is the number of target genes that are in both conditions.</p>')\n",
    "#         make_comparison_table(f, gene_lists, agi2genename_dict, SUMMARY_DIR)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    \n",
    "    file_bindingMat = 'FoldChange_table.csv' #% SUMMARY_DIR\n",
    "   \n",
    "    f.write('<h3>Binding to target genes in different conditions</h3>')\n",
    "    f.write('<p><b>Note:</b> In the following, \\'+\\' means binding near a target gene in a particular experimental condition, and \\'-\\' means non-binding.</p>')\n",
    "    f.write('<p>The columns are:<br/><br/>')\n",
    "    colName = ['AGI_locus_name'] + [d['key'] for d in res] + ['gene_name (if available)']\n",
    "    f.write( '<br/>'.join(colName))\n",
    "    f.write('</p>')\n",
    "    f.write('<p><a href=\\\"%s\\\">Download text version</a></p>' % (file_bindingMat))\n",
    "\n",
    "    f.write('</body>')    \n",
    "    f.write('</html>')    \n",
    "    f.close()\n",
    "\n",
    "\n",
    "    # clean up\n",
    "    print('Done.')\n",
    "    \n",
    "#         delete_file('a.txt')\n",
    "#         delete_file('a2.txt')\n",
    "#         delete_file('b.txt')\n",
    "#         delete_file('c.txt')\n",
    "#         delete_file('d.txt')\n",
    "#         delete_file('temp_gene_list.txt')\n",
    "#         delete_file('temp_small.narrowPeak')\n",
    "#         delete_file('predicctd')\n",
    "#         delete_file('macs2-predictd.txt')\n",
    "#         delete_file('predictd')\n",
    "#         delete_files('*.xls')\n",
    "#         delete_files('*.bed')\n",
    "#         delete_files('*_peaks.narrowPeak')\n",
    "# #         delete_files('AGI2-*.txt')\n",
    "# #         delete_files('AGI2*.txt')\n",
    "#         delete_files('small_*.narrowPeak.txt')\n",
    "#         move_files('pipeline_*.sh', SUMMARY_DIR)\n",
    "\n",
    "import os, argparse\n",
    "import pymisca.util as pyutil\n",
    "import pandas as pd\n",
    "import synotil.util as sutil\n",
    "import synotil.countMatrix as scount\n",
    "import StringIO\n",
    "if __name__=='__main__':\n",
    "    #############################################################################################\n",
    "\n",
    "    DEPENDENT_FILES_PATH        = '/media/pw_synology3/Software/chip-summary/'  # [path of chip-summary.py]\n",
    "    DEFAULT_TARGET_RANGE        = '3000' # [change]  a string, not a number\n",
    "    SUMMARY_FILE_NAME           = 'summary.html'\n",
    "    SUMMARY_DIR                 = 'summary'\n",
    "    PEAK_CALL_PIPELINE_TEMPLATE = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/pipeline724-t.sh')\n",
    "    PEAK_SELECT_SCRIPT          = ('/media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py')\n",
    "    GENELOCUS_TO_GENENAME_SCRIPT=('/media/pw_synology3/Software/chip-summary/depend/script/genelocus2genename.py')\n",
    "    \n",
    "    #### Slowest part to be refactored???\n",
    "    EXTRACT_AGI_CODE_AND_FC     = ('/media/pw_synology3/Software/chip-summary/depend/script/extract_AGI_code_and_fold_change.py')\n",
    "    GO_ENRICHMENT_SCRIPT        = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/fe.sh')  # install goatools (GO enrichment) and edit fe.sh\n",
    "    GO_ENRICHMENT_DIFF_SCRIPT   = os.path.join(DEPENDENT_FILES_PATH, 'depend/script/goterm-matrix.py')\n",
    "    AGI_TO_GENE_NAMES           = ('/media/pw_synology3/Software/chip-summary/depend/data/AGI-to-gene-names.txt')\n",
    "    ANNOTATION_FILE             = os.path.join(DEPENDENT_FILES_PATH, 'depend/data/genesTAIR10.bed') # for bedmap\n",
    "    GENE_DESCRIPTION            = ('/media/pw_synology3/Software/chip-summary/depend/data/gene_description_20140101.txt')\n",
    "    MAX_FOLD_CHANGE             = 10  # for number of peaks versus fold-change plot\n",
    "\n",
    "    #############################################################################################\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-v', action='store_true')\n",
    "    parser.add_argument('infiles', nargs='+', default=[],\n",
    "                       help='*.narrowPeak files to be summarised')\n",
    "    parser.add_argument('--ref','-r', nargs='?',\n",
    "                        default='/media/pw_synology3/Software/chip-summary/depend/data/genesTAIR10.bed',\n",
    "                       help='reference annotation')\n",
    "    parser.add_argument('--output_dir','-o', nargs='?',\n",
    "                        default='chipSum',\n",
    "                       help='reference annotation')\n",
    "    parser.add_argument('--FC',nargs='?',type=float,\n",
    "                        default= 1.5 ,\n",
    "                        help='')\n",
    "    parser.add_argument('--PVALUE',nargs='?',type=float,\n",
    "                        default= 0.01 ,\n",
    "                        help='')\n",
    "    parser.add_argument('--QVALUE',nargs='?',type=float,\n",
    "                        default= 0.01 ,\n",
    "                        help='')\n",
    "    args =  parser.parse_args()\n",
    "    ANNOTATION_FILE   = os.path.abspath(args.ref)\n",
    "    infiles = map(os.path.abspath, args.infiles)\n",
    "\n",
    "    VAR = 'GSIZE'\n",
    "    assert VAR in os.environ, 'Cannot find bash environ: $%s'%VAR\n",
    "    \n",
    "    dbg = int(args.v)*10\n",
    "\n",
    "    os.system('mkdir -p %s'%args.output_dir)\n",
    "    os.chdir(args.output_dir)\n",
    "    cmd= '''\n",
    "mkdir -p summary; \n",
    "mkdir -p summary/npeaks_vs_fc_npk;\n",
    "mkdir -p summary/npk;\n",
    "cp -r {infiles} -t .\n",
    "'''.format(\n",
    "    infiles=' '.join(infiles))\n",
    "    os.system(cmd)\n",
    "\n",
    "    agi2genename_dict = make_AGI_to_gene_name_dict(AGI_TO_GENE_NAMES)\n",
    "    \n",
    "    peakSummary(infiles,\n",
    "                dbg=dbg,\n",
    "                **args.__dict__)\n",
    "    \n",
    "    SUMMARY_DIR = SUMMARY_DIR.rstrip('/')\n",
    "    os.system('mkdir -p %s/peaks' % SUMMARY_DIR)\n",
    "    # os.system('cp *_peaks.narrowPeak *.bed *.xls %s/peaks' % SUMMARY_DIR)\n",
    "\n",
    "    #         res = {k:process(k) for k in condDict}\n",
    "\n",
    "    sys.exit(0)\n",
    "#     args =  parser.parse_args\n",
    "#     parser.\n",
    "#     parser\n",
    "#     ## main #####################################################\n",
    "#     if len(sys.argv) < 2:\n",
    "#         print('Usage: python chip-summary.py summary.txt')\n",
    "#         sys.exit()\n",
    "\n",
    "#     # make sure path to chip-summary is set correctly\n",
    "#     if not os.path.exists(PEAK_CALL_PIPELINE_TEMPLATE):\n",
    "#         print('Set DEPENDENT_FILES_PATH in chip-summary.py the path of chip-summary.')\n",
    "#         sys.exit()\n",
    "#     else:\n",
    "#         print('\\nTips: set DEPENDENT_FILES_PATH in chip-summary.py to the full path of chip-summary (e.g., %s).\\n      Then chip-summary.py is executable in other directories.\\n') % (os.getcwd())\n",
    "\n",
    "\n",
    "#     # make sure macs2 and bedmap are installed\n",
    "#     program_installed('macs2')\n",
    "#     program_installed('bedmap')\n",
    "\n",
    "#     # make sure goatools is installed\n",
    "#     goatools_installed()\n",
    "\n",
    "\n",
    "#     f = sys.argv[1]\n",
    "#      main(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Tool:    bedtools closest (aka closestBed)\r\n",
      "Version: v2.27.1\r\n",
      "Summary: For each feature in A, finds the closest \r\n",
      "\t feature (upstream or downstream) in B.\r\n",
      "\r\n",
      "Usage:   bedtools closest [OPTIONS] -a <bed/gff/vcf> -b <bed/gff/vcf>\r\n",
      "\r\n",
      "Options: \r\n",
      "\t-d\tIn addition to the closest feature in B, \r\n",
      "\t\treport its distance to A as an extra column.\r\n",
      "\t\t- The reported distance for overlapping features will be 0.\r\n",
      "\r\n",
      "\t-D\tLike -d, report the closest feature in B, and its distance to A\r\n",
      "\t\tas an extra column. Unlike -d, use negative distances to report\r\n",
      "\t\tupstream features.\r\n",
      "\t\tThe options for defining which orientation is \"upstream\" are:\r\n",
      "\t\t- \"ref\"   Report distance with respect to the reference genome. \r\n",
      "\t\t            B features with a lower (start, stop) are upstream\r\n",
      "\t\t- \"a\"     Report distance with respect to A.\r\n",
      "\t\t            When A is on the - strand, \"upstream\" means B has a\r\n",
      "\t\t            higher (start,stop).\r\n",
      "\t\t- \"b\"     Report distance with respect to B.\r\n",
      "\t\t            When B is on the - strand, \"upstream\" means A has a\r\n",
      "\t\t            higher (start,stop).\r\n",
      "\r\n",
      "\t-io\tIgnore features in B that overlap A.  That is, we want close,\r\n",
      "\t\tyet not touching features only.\r\n",
      "\r\n",
      "\t-iu\tIgnore features in B that are upstream of features in A.\r\n",
      "\t\tThis option requires -D and follows its orientation\r\n",
      "\t\trules for determining what is \"upstream\".\r\n",
      "\r\n",
      "\t-id\tIgnore features in B that are downstream of features in A.\r\n",
      "\t\tThis option requires -D and follows its orientation\r\n",
      "\t\trules for determining what is \"downstream\".\r\n",
      "\r\n",
      "\t-fu\tChoose first from features in B that are upstream of features in A.\r\n",
      "\t\tThis option requires -D and follows its orientation\r\n",
      "\t\trules for determining what is \"upstream\".\r\n",
      "\r\n",
      "\t-fd\tChoose first from features in B that are downstream of features in A.\r\n",
      "\t\tThis option requires -D and follows its orientation\r\n",
      "\t\trules for determining what is \"downstream\".\r\n",
      "\r\n",
      "\t-t\tHow ties for closest feature are handled.  This occurs when two\r\n",
      "\t\tfeatures in B have exactly the same \"closeness\" with A.\r\n",
      "\t\tBy default, all such features in B are reported.\r\n",
      "\t\tHere are all the options:\r\n",
      "\t\t- \"all\"    Report all ties (default).\r\n",
      "\t\t- \"first\"  Report the first tie that occurred in the B file.\r\n",
      "\t\t- \"last\"   Report the last tie that occurred in the B file.\r\n",
      "\r\n",
      "\t-mdb\tHow multiple databases are resolved.\r\n",
      "\t\t- \"each\"    Report closest records for each database (default).\r\n",
      "\t\t- \"all\"  Report closest records among all databases.\r\n",
      "\r\n",
      "\t-k\tReport the k closest hits. Default is 1. If tieMode = \"all\", \r\n",
      "\t\t- all ties will still be reported.\r\n",
      "\r\n",
      "\t-N\tRequire that the query and the closest hit have different names.\r\n",
      "\t\tFor BED, the 4th column is compared.\r\n",
      "\r\n",
      "\t-s\tRequire same strandedness.  That is, only report hits in B\r\n",
      "\t\tthat overlap A on the _same_ strand.\r\n",
      "\t\t- By default, overlaps are reported without respect to strand.\r\n",
      "\r\n",
      "\t-S\tRequire different strandedness.  That is, only report hits in B\r\n",
      "\t\tthat overlap A on the _opposite_ strand.\r\n",
      "\t\t- By default, overlaps are reported without respect to strand.\r\n",
      "\r\n",
      "\t-f\tMinimum overlap required as a fraction of A.\r\n",
      "\t\t- Default is 1E-9 (i.e., 1bp).\r\n",
      "\t\t- FLOAT (e.g. 0.50)\r\n",
      "\r\n",
      "\t-F\tMinimum overlap required as a fraction of B.\r\n",
      "\t\t- Default is 1E-9 (i.e., 1bp).\r\n",
      "\t\t- FLOAT (e.g. 0.50)\r\n",
      "\r\n",
      "\t-r\tRequire that the fraction overlap be reciprocal for A AND B.\r\n",
      "\t\t- In other words, if -f is 0.90 and -r is used, this requires\r\n",
      "\t\t  that B overlap 90% of A and A _also_ overlaps 90% of B.\r\n",
      "\r\n",
      "\t-e\tRequire that the minimum fraction be satisfied for A OR B.\r\n",
      "\t\t- In other words, if -e is used with -f 0.90 and -F 0.10 this requires\r\n",
      "\t\t  that either 90% of A is covered OR 10% of  B is covered.\r\n",
      "\t\t  Without -e, both fractions would have to be satisfied.\r\n",
      "\r\n",
      "\t-split\tTreat \"split\" BAM or BED12 entries as distinct BED intervals.\r\n",
      "\r\n",
      "\t-g\tProvide a genome file to enforce consistent chromosome sort order\r\n",
      "\t\tacross input files. Only applies when used with -sorted option.\r\n",
      "\r\n",
      "\t-nonamecheck\tFor sorted data, don't throw an error if the file has different naming conventions\r\n",
      "\t\t\tfor the same chromosome. ex. \"chr1\" vs \"chr01\".\r\n",
      "\r\n",
      "\t-names\tWhen using multiple databases, provide an alias for each that\r\n",
      "\t\twill appear instead of a fileId when also printing the DB record.\r\n",
      "\r\n",
      "\t-filenames\tWhen using multiple databases, show each complete filename\r\n",
      "\t\t\tinstead of a fileId when also printing the DB record.\r\n",
      "\r\n",
      "\t-sortout\tWhen using multiple databases, sort the output DB hits\r\n",
      "\t\t\tfor each record.\r\n",
      "\r\n",
      "\t-bed\tIf using BAM input, write output as BED.\r\n",
      "\r\n",
      "\t-header\tPrint the header from the A file prior to results.\r\n",
      "\r\n",
      "\t-nobuf\tDisable buffered output. Using this option will cause each line\r\n",
      "\t\tof output to be printed as it is generated, rather than saved\r\n",
      "\t\tin a buffer. This will make printing large output files \r\n",
      "\t\tnoticeably slower, but can be useful in conjunction with\r\n",
      "\t\tother software tools and scripts that need to process one\r\n",
      "\t\tline of bedtools output at a time.\r\n",
      "\r\n",
      "\t-iobuf\tSpecify amount of memory to use for input buffer.\r\n",
      "\t\tTakes an integer argument. Optional suffixes K/M/G supported.\r\n",
      "\t\tNote: currently has no effect with compressed files.\r\n",
      "\r\n",
      "Notes: \r\n",
      "\tReports \"none\" for chrom and \"-1\" for all other fields when a feature\r\n",
      "\tis not found in B on the same chromosome as the feature in A.\r\n",
      "\tE.g. none\t-1\t-1\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "***** ERROR: No input file given. Exiting. *****\r\n"
     ]
    }
   ],
   "source": [
    "!bedtools closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chrom',\n",
       " 'start',\n",
       " 'end',\n",
       " 'acc',\n",
       " 'score',\n",
       " 'strand',\n",
       " 'FC',\n",
       " 'neglogPval',\n",
       " 'neglogQval',\n",
       " 'summit']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sutil.bedHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Cannot find file:key.gene\n"
     ]
    }
   ],
   "source": [
    "reload(sutil)\n",
    "??sutil.parseBedmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyutil.Table2Mat??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is in ipython: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Table2Mat',\n",
       " 'df2flat',\n",
       " 'flat2meta',\n",
       " 'f_2d',\n",
       " 'meta2name',\n",
       " 'cov2cor',\n",
       " 'arg2dict',\n",
       " 'pd2md',\n",
       " 'model2eqn',\n",
       " 'mat2latex',\n",
       " 'mat2str',\n",
       " 'l2_normF',\n",
       " 'mapper_2d',\n",
       " 'meta2flat',\n",
       " 'fname2mdpic',\n",
       " 'flat2dict',\n",
       " 'dict2flat']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyutil.d\n",
    "reload(pyutil)\n",
    "# pyutil.addFl\n",
    "# sutil.dfContrast\n",
    "[ f for f in pyutil.__dict__.keys() if '2' in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import synotil.countMatrix as scount\n",
    "# import pyutil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load '/media/pw_synology3/Software/chip-summary/depend/script/extract_AGI_code_and_fold_change.py'\n",
    "import codecs\n",
    "import sys\n",
    "f = codecs.open(sys.argv[1], 'r', 'utf-8')\n",
    "\n",
    "L = []\n",
    "\n",
    "d = {}\n",
    "\n",
    "\n",
    "print('\\t'.join(['AGI_code', 'max_fold_change_in_nearby_peaks']))\n",
    "def splittedname(s):\n",
    "    return tuple(int(x) for x in s.split('.'))\n",
    "    \n",
    "for line in f:\n",
    "    lst = line.split()\n",
    "    for x in lst:\n",
    "        if x.lower().startswith('at') and len(x) >= 9 and x[2].isdigit():\n",
    "            if lst[6].find('affects') != -1:\n",
    "                print(line)\n",
    "                sys.exit()\n",
    "            gene = x[0:9].upper()\n",
    "            if not gene in d:\n",
    "                d[gene] = lst[6]\n",
    "            else:\n",
    "                d[gene] += '\\t' + lst[6]\n",
    "\n",
    "for x in sorted(d):\n",
    "    s = '%s' % (x)\n",
    "    s += '\\t'\n",
    "    value = d[x]\n",
    "    l = sorted(value.split(), key=splittedname, reverse=True)\n",
    "    s += l[0]\n",
    "    print(s)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pymisca.util.ppJson>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /media/pw_synology3/Software/chip-summary/depend/script/genelocus2genename.py\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "def get_description(x, d):\n",
    "        result = ''\n",
    "\tif 0 < len(x) <= 9:\n",
    "\t\tx = x + '.1' \n",
    "\tif x in d:\n",
    "\t        result += '    ' + x + ':    ' + d[x]\n",
    "\telse:\n",
    "\t\tresult += '    ' + x + ': Not Found'\n",
    "        return result\n",
    "        \n",
    "locus_file = sys.argv[1]\n",
    "f0 = open(sys.argv[2]) # gene description file, e.g., /media/pw_synology3/Software/chip-summary/depend/data/gene_description_20140101.txt\n",
    "\n",
    "d = {}\n",
    "for line in f0:\n",
    "\tline = line.strip()\n",
    "\tlst = line.split()\n",
    "\tid = lst[0]\n",
    "\tif not id in d:\n",
    "\t\td[id] = line\n",
    "\n",
    "f0.close()\n",
    "\n",
    "if  not os.path.isfile(locus_file):  # gene names provided as a string\n",
    "        line = locus_file\n",
    "        line = line.replace('\\\"', '')\n",
    "        lst = line.split(';')\n",
    "        result = ''\n",
    "        for x in lst:\n",
    "                result += get_description(x.upper(), d)\n",
    "        print(result)\n",
    "else:\n",
    "        f = open(locus_file)\n",
    "\n",
    "        for line in f:\n",
    "\t        line = line.strip()\n",
    "\t        line = line.replace('\\\"', '')\n",
    "\t        lst = line.split(';')\n",
    "\t        result = ''\n",
    "\t        for x in lst:\n",
    "                        result += get_description(x, d)\n",
    "\t        print(result)\n",
    "\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /media/pw_synology3/Software/chip-summary/depend/script/pipeline724-t.sh\n",
    "# NCIS\n",
    "est_scale_factor=\"n\"\n",
    "est_extension_size=\"y\"\n",
    "\n",
    "# peak call parameters\n",
    "pvalue=\"0.05\"\n",
    "qvalue=\"0\"\n",
    "\n",
    "if [ \"$est_scale_factor\" = \"y\" ]\n",
    "then\n",
    "    echo \"Estimate scaling factor ...\"    \n",
    "    temp_name=$(cat /dev/urandom | tr -dc 'A-Z' | fold -w 6 | head -n 1)\n",
    "    echo \"$temp_name\"\n",
    "    echo \"    Convert BAM files to BED files \"\n",
    "    bedtools bamtobed -i $chip > \"$temp_name\"\"_chip.bed\"\n",
    "    bedtools bamtobed -i $input > \"$temp_name\"\"_input.bed\"\n",
    "    echo \"    Estimate (it may take one hour)\"\n",
    "    Rscript /home/hui/script/estimate_scaling_factor.r \"$temp_name\"\"_chip.bed\" \"$temp_name\"\"_input.bed\"\n",
    "    ratio=$(cat scale-factor.txt)\n",
    "    rm -f \"${temp_name}*.bed\"\n",
    "fi\n",
    "\n",
    "\n",
    "if [ \"$est_extension_size\" = \"y\" ]\n",
    "then\n",
    "    echo \"Estimate fragment size ...\"\n",
    "    macs2 predictd -i $chip &> macs2-predictd.txt\n",
    "    extsize=$(grep \"predicted fragment length\" macs2-predictd.txt  | grep -Po '[0-9]+ bps' | tr -d 'a-z')\n",
    "    echo \"    the estimated d is $extsize\"\n",
    "fi\n",
    "\n",
    "\n",
    "echo \"Save results in file names started with $name\"\n",
    "additional_arguments_for_macs2=\" --nomodel \"\n",
    "if [ \"$est_scale_factor\" = \"y\" ]\n",
    "then\n",
    "    additional_arguments_for_macs2=\"$additional_arguments_for_macs2 --ratio $ratio\"\n",
    "fi\n",
    "\n",
    "if [ \"$pvalue\" != \"0\" ]\n",
    "then\n",
    "    additional_arguments_for_macs2=\"$additional_arguments_for_macs2 -p $pvalue\"\n",
    "fi\n",
    "\n",
    "if [ \"$qvalue\" != \"0\" ]\n",
    "then\n",
    "    additional_arguments_for_macs2=\"$additional_arguments_for_macs2 -q $qvalue\"\n",
    "fi\n",
    "\n",
    "if [ \"$est_extension_size\" = \"y\" ]\n",
    "then\n",
    "    additional_arguments_for_macs2=\"$additional_arguments_for_macs2 --extsize $extsize\"\n",
    "fi\n",
    "\n",
    "echo \"Call peaks ...\"\n",
    "macs2 callpeak -t $chip -c $input -f BAM -g 121576530 --keep-dup 1 -n $name $additional_arguments_for_macs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(infiles=['test1', 'test2'], v=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test1', 'test2']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-v', action='store_true')\n",
    "    parser.add_argument('infiles', nargs='+', default=[])\n",
    "    args =  parser.parse_args()\n",
    "\n",
    "args =  parser.parse_args('test1 test2 -v'.split())\n",
    "print args\n",
    "args.infiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find .. -name \"*_peaks.narrowPeak\" -exec ls -lSH {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find .. -name *_peaks.narrowPeak -exec ls -S {} + | head -n3 | xargs -i ln {} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is in ipython: 1\n"
     ]
    }
   ],
   "source": [
    "import main;reload(main);from main import *\n",
    "# d = main('test.config',dbg=1)\n",
    "import pymisca.util as pyutil;reload(pyutil)\n",
    "npkFS = !ls *.narrowPeak\n",
    "# d = peakSummary(npkFS,dbg=0)\n",
    "# for dd in d:\n",
    "#     print pyutil.ppJson(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py 182C_S15_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > 182C_S15_peaks.snpk\n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/extract_AGI_code_and_fold_change.py d.txt\n"
     ]
    }
   ],
   "source": [
    "gPar = None or {\n",
    "    \"FC\": 1.5, \n",
    "    \"PAIRWISE_COMPARE\": \"Y\", \n",
    "    \"PVALUE\": 0.01, \n",
    "    \"QVALUE\": 0.0005, \n",
    "    \"TARGET_RANGE\": \"3000\", \n",
    "    \"TITLE\": \"testRun\"\n",
    "}\n",
    "%load_ext line_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f peakSummary peakSummary(npkFS[:1],dbg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py 182C_S15_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > 182C_S15_peaks.snpk\n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/extract_AGI_code_and_fold_change.py d.txt\n"
     ]
    }
   ],
   "source": [
    "%lprun -f process process(npkFile=npkFS[0],gPar=gPar,dbg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/feng/repos/BrachyPhoton/pipeline_rnaseq/pipeline_macs2.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/feng/repos/BrachyPhoton/pipeline_rnaseq/pipeline_macs2.sh\n",
    "#!/bin/bash\n",
    "main()\n",
    "{\n",
    "    local PROG=macs2\n",
    "    local SELF=${BASH_SOURCE}\n",
    "    local SELF_ALI=`basename ${SELF%.*}`\n",
    "    \n",
    "    local BAM=$1  ### input bam file\n",
    "    GCOUNT=${2:-`size2sum $GSIZE`} ### lenght of your genome\n",
    "    ALI=`basename ${BAM%.*}`\n",
    "    CMD=\"macs2 callpeak -t $BAM --keep-dup 1 -n $ALI -g $GCOUNT\"    \n",
    "    runWithTimeLog \"$CMD\" | tail -1 >> ${ALI}.time\n",
    "}\n",
    "main \"$@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execfile('../../Brachy/header_0626.py')\n",
    "pyutil.envSource('/home/feng/envs/pipeline_Bd/bin/activate',dry=0,silent=1);\n",
    "pyutil.envSource('/home/feng/envs/pipeline_Bd/bin/config_Bd21-3.sh',dry=0,silent=1);\n",
    "pyutil.envSource(pyutil.os.environ['UTIL'],dry=0,silent=1);\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to /home/feng/repos/BrachyPhoton/util.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a /home/feng/repos/BrachyPhoton/util.sh\n",
    "\n",
    "runWithTimeLog()\n",
    "{\n",
    "    local CMD=\"$@\"\n",
    "    local ALI=${ALI:-testALI}\n",
    "    local PROG=${PROG:-testPROG}\n",
    "    local T0 T1 Tdiff\n",
    "    local SELF=${SELF:-testScript.sh}\n",
    "    \n",
    "#     echo $CMD\n",
    "    [[ $DRY -eq 1 ]] || {\n",
    "        T0=`datefloat`\n",
    "        $CMD 2>&1 | tee ${ALI}.${PROG}.log \n",
    "        T1=`datefloat`\n",
    "        Tdiff=`echo $T1 - $T0 | bc`\n",
    "        echo $SELF,$Tdiff,\\\"$CMD\\\"\n",
    "    }\n",
    "}\n",
    "export -f runWithTimeLog\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGI_code\\tmax_fold_change_in_nearby_peaks\\nAT1G01060\\t3.31494\\nAT1G01070\\t3.31494\\nAT1G01090\\t8.55063\\nAT1G0'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra': '',\n",
       " 'files': {},\n",
       " 'genes': {},\n",
       " 'glst_filename': 'summary/182C_S15_peaks_gene_list.txt',\n",
       " 'goenrich_filename': 'summary/182C_S15_peaks_GOenrichment.txt',\n",
       " 'key': '182C_S15_peaks',\n",
       " 'nGene': 0,\n",
       " 'param': 'fc=1.5 q=0.001 p=0.01',\n",
       " 'peak_file': '182C_S15_peaks.snpk',\n",
       " 'plot_file': 'summary/npeaks_vs_fc_182C_S15_peaks.txt'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chmod: changing permissions of 'chip-summary.py': Operation not permitted\n",
      "is in ipython: 0\n",
      "\n",
      "Tips: set DEPENDENT_FILES_PATH in chip-summary.py to the full path of chip-summary (e.g., /home/feng/envs/164C/dev).\n",
      "      Then chip-summary.py is executable in other directories.\n",
      "\n",
      "['/home/feng/temp/test/test_1per.bam']\n",
      "['/home/feng/temp/test/test_1per.bam']\n",
      "Run pipeline_test_1percent.sh ...\n",
      "Estimate fragment size ...\n",
      "    the estimated d is 66 \n",
      "Save results in file names started with test_1percent\n",
      "Call peaks ...\n",
      "INFO  @ Fri, 15 Jun 2018 11:08:30: \n",
      "# Command line: callpeak -t /home/feng/temp/test/test_1per.bam -c /home/feng/temp/test/test_1per.bam -f BAM -g 121576530 --keep-dup 1 -n test_1percent --nomodel -p 0.05 --extsize 66\n",
      "# ARGUMENTS LIST:\n",
      "# name = test_1percent\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['/home/feng/temp/test/test_1per.bam']\n",
      "# control file = ['/home/feng/temp/test/test_1per.bam']\n",
      "# effective genome size = 1.22e+08\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# pvalue cutoff = 5.00e-02\n",
      "# qvalue will not be calculated and reported as -1 in the final output.\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      " \n",
      "INFO  @ Fri, 15 Jun 2018 11:08:30: #1 read tag files... \n",
      "INFO  @ Fri, 15 Jun 2018 11:08:30: #1 read treatment tags... \n",
      "INFO  @ Fri, 15 Jun 2018 11:08:41:  1000000 \n",
      "INFO  @ Fri, 15 Jun 2018 11:08:53:  2000000 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:01: #1.2 read input tags... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:12:  1000000 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:23:  2000000 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 tag size is determined as 74 bps \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 tag size = 74 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1  total tags in treatment: 855832 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 user defined the maximum tags... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1  tags after filtering in treatment: 588107 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1  Redundant rate of treatment: 0.31 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1  total tags in control: 855832 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 user defined the maximum tags... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1  tags after filtering in control: 588107 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1  Redundant rate of control: 0.31 \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #1 finished! \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #2 Build Peak Model... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #2 Skipped... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #2 Use 66 as fragment length \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #3 Call peaks... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #3 Call peaks with given -log10pvalue cutoff: 1.30103 ... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:31: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:39: #3 Call peaks for each chromosome... \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:42: #4 Write output xls file... test_1percent_peaks.xls \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:42: #4 Write peak in narrowPeak format file... test_1percent_peaks.narrowPeak \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:42: #4 Write summits bed file... test_1percent_summits.bed \n",
      "INFO  @ Fri, 15 Jun 2018 11:09:42: Done! \n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py summary/peaks/test_1percent_peaks.narrowPeak fc=1.5 q=0.0005 p=0.01 > small_test_1percent.narrowPeak.txt\n",
      "... make html page summary.html\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!chmod +x *.py\n",
    "!./main.py test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 182C_Ath.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile 182C_Ath.config\n",
    "%%FC=1.5 QVALUE=0.001 PVALUE=0.01\n",
    "%%PAIRWISE_COMPARE=Y\n",
    "%%TITLE=182C_Ath\n",
    "\n",
    "@182C_S15\n",
    "CHIP:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S15/*.bam\n",
    "INPUT:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/*_picard.bam\n",
    "    \n",
    "@182C_S16\n",
    "CHIP:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S16/*.bam\n",
    "INPUT:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/*_picard.bam\n",
    "@182C_S17\n",
    "CHIP:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S17/*.bam\n",
    "INPUT:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/*_picard.bam\n",
    "@182C_S18\n",
    "CHIP:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S18/*.bam\n",
    "INPUT:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/*_picard.bam\n",
    "@176C_INPUT\n",
    "CHIP:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/*_picard.bam\n",
    "INPUT:/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/*_picard.bam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chmod: changing permissions of 'chip-summary.py': Operation not permitted\n",
      "is in ipython: 0\n",
      "\n",
      "Tips: set DEPENDENT_FILES_PATH in chip-summary.py to the full path of chip-summary (e.g., /home/feng/envs/164C/dev).\n",
      "      Then chip-summary.py is executable in other directories.\n",
      "\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S15/1505-17C-ZT0_S15.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S16/1505-17C-ZT16_S16.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S17/1505-27C-ZT0_S17.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S18/1505-27C-ZT16_S18.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "Run pipeline_182C_S15.sh ...\n",
      "Estimate fragment size ...\n",
      "    the estimated d is 258 \n",
      "Save results in file names started with 182C_S15\n",
      "Call peaks ...\n",
      "INFO  @ Thu, 14 Jun 2018 18:14:22: \n",
      "# Command line: callpeak -t /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S15/1505-17C-ZT0_S15.bam -c /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam -f BAM -g 121576530 --keep-dup 1 -n 182C_S15 --nomodel -p 0.05 --extsize 258\n",
      "# ARGUMENTS LIST:\n",
      "# name = 182C_S15\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S15/1505-17C-ZT0_S15.bam']\n",
      "# control file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "# effective genome size = 1.22e+08\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# pvalue cutoff = 5.00e-02\n",
      "# qvalue will not be calculated and reported as -1 in the final output.\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      " \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:22: #1 read tag files... \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:22: #1 read treatment tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:29:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:35:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:42:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:49:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:14:55:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:02:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:08:  7000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:15:  8000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:20: #1.2 read input tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:29:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:35:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:42:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:48:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:15:55:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:01:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:06: #1 tag size is determined as 71 bps \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:06: #1 tag size = 71 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:06: #1  total tags in treatment: 8814077 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:06: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:06: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1  tags after filtering in treatment: 8814077 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1  Redundant rate of treatment: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1  total tags in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1  tags after filtering in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1  Redundant rate of control: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #1 finished! \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #2 Build Peak Model... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #2 Skipped... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #2 Use 258 as fragment length \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #3 Call peaks... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #3 Call peaks with given -log10pvalue cutoff: 1.30103 ... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:07: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Thu, 14 Jun 2018 18:16:54: #3 Call peaks for each chromosome... \n",
      "INFO  @ Thu, 14 Jun 2018 18:17:09: #4 Write output xls file... 182C_S15_peaks.xls \n",
      "INFO  @ Thu, 14 Jun 2018 18:17:09: #4 Write peak in narrowPeak format file... 182C_S15_peaks.narrowPeak \n",
      "INFO  @ Thu, 14 Jun 2018 18:17:09: #4 Write summits bed file... 182C_S15_summits.bed \n",
      "INFO  @ Thu, 14 Jun 2018 18:17:09: Done! \n",
      "Run pipeline_182C_S16.sh ...\n",
      "Estimate fragment size ...\n",
      "    the estimated d is 227 \n",
      "Save results in file names started with 182C_S16\n",
      "Call peaks ...\n",
      "INFO  @ Thu, 14 Jun 2018 18:20:42: \n",
      "# Command line: callpeak -t /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S16/1505-17C-ZT16_S16.bam -c /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam -f BAM -g 121576530 --keep-dup 1 -n 182C_S16 --nomodel -p 0.05 --extsize 227\n",
      "# ARGUMENTS LIST:\n",
      "# name = 182C_S16\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S16/1505-17C-ZT16_S16.bam']\n",
      "# control file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "# effective genome size = 1.22e+08\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# pvalue cutoff = 5.00e-02\n",
      "# qvalue will not be calculated and reported as -1 in the final output.\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      " \n",
      "INFO  @ Thu, 14 Jun 2018 18:20:42: #1 read tag files... \n",
      "INFO  @ Thu, 14 Jun 2018 18:20:42: #1 read treatment tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:20:56:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:21:11:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:21:25:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:21:39:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:21:54:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:22:08:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:22:22:  7000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:22:37:  8000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:22:51:  9000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:23:05:  10000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:23:19:  11000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:23:34:  12000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:23:48:  13000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:23:51: #1.2 read input tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:24:04:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:24:18:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:24:32:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:24:47:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:01:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:15:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:27: #1 tag size is determined as 63 bps \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:27: #1 tag size = 63 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:27: #1  total tags in treatment: 13204194 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:27: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:27: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1  tags after filtering in treatment: 13204194 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1  Redundant rate of treatment: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1  total tags in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1  tags after filtering in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1  Redundant rate of control: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #1 finished! \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #2 Build Peak Model... \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #2 Skipped... \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #2 Use 227 as fragment length \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #3 Call peaks... \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #3 Call peaks with given -log10pvalue cutoff: 1.30103 ... \n",
      "INFO  @ Thu, 14 Jun 2018 18:25:28: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Thu, 14 Jun 2018 18:27:19: #3 Call peaks for each chromosome... \n",
      "INFO  @ Thu, 14 Jun 2018 18:27:59: #4 Write output xls file... 182C_S16_peaks.xls \n",
      "INFO  @ Thu, 14 Jun 2018 18:27:59: #4 Write peak in narrowPeak format file... 182C_S16_peaks.narrowPeak \n",
      "INFO  @ Thu, 14 Jun 2018 18:27:59: #4 Write summits bed file... 182C_S16_summits.bed \n",
      "INFO  @ Thu, 14 Jun 2018 18:27:59: Done! \n",
      "Run pipeline_182C_S17.sh ...\n",
      "Estimate fragment size ...\n",
      "    the estimated d is 288 \n",
      "Save results in file names started with 182C_S17\n",
      "Call peaks ...\n",
      "INFO  @ Thu, 14 Jun 2018 18:29:00: \n",
      "# Command line: callpeak -t /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S17/1505-27C-ZT0_S17.bam -c /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam -f BAM -g 121576530 --keep-dup 1 -n 182C_S17 --nomodel -p 0.05 --extsize 288\n",
      "# ARGUMENTS LIST:\n",
      "# name = 182C_S17\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S17/1505-27C-ZT0_S17.bam']\n",
      "# control file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "# effective genome size = 1.22e+08\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# pvalue cutoff = 5.00e-02\n",
      "# qvalue will not be calculated and reported as -1 in the final output.\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      " \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:00: #1 read tag files... \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:00: #1 read treatment tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:08:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:14:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:21:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:27:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:34:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:40:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:45: #1.2 read input tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:29:55:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:01:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:08:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:15:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:21:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:28:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 tag size is determined as 59 bps \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 tag size = 59 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1  total tags in treatment: 6652751 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1  tags after filtering in treatment: 6652751 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1  Redundant rate of treatment: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1  total tags in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1  tags after filtering in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1  Redundant rate of control: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #1 finished! \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #2 Build Peak Model... \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #2 Skipped... \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #2 Use 288 as fragment length \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #3 Call peaks... \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #3 Call peaks with given -log10pvalue cutoff: 1.30103 ... \n",
      "INFO  @ Thu, 14 Jun 2018 18:30:33: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Thu, 14 Jun 2018 18:31:19: #3 Call peaks for each chromosome... \n",
      "INFO  @ Thu, 14 Jun 2018 18:31:33: #4 Write output xls file... 182C_S17_peaks.xls \n",
      "INFO  @ Thu, 14 Jun 2018 18:31:33: #4 Write peak in narrowPeak format file... 182C_S17_peaks.narrowPeak \n",
      "INFO  @ Thu, 14 Jun 2018 18:31:33: #4 Write summits bed file... 182C_S17_summits.bed \n",
      "INFO  @ Thu, 14 Jun 2018 18:31:33: Done! \n",
      "Run pipeline_182C_S18.sh ...\n",
      "Estimate fragment size ...\n",
      "    the estimated d is 287 \n",
      "Save results in file names started with 182C_S18\n",
      "Call peaks ...\n",
      "INFO  @ Thu, 14 Jun 2018 18:32:58: \n",
      "# Command line: callpeak -t /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S18/1505-27C-ZT16_S18.bam -c /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam -f BAM -g 121576530 --keep-dup 1 -n 182C_S18 --nomodel -p 0.05 --extsize 287\n",
      "# ARGUMENTS LIST:\n",
      "# name = 182C_S18\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/182C/S18/1505-27C-ZT16_S18.bam']\n",
      "# control file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "# effective genome size = 1.22e+08\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# pvalue cutoff = 5.00e-02\n",
      "# qvalue will not be calculated and reported as -1 in the final output.\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      " \n",
      "INFO  @ Thu, 14 Jun 2018 18:32:58: #1 read tag files... \n",
      "INFO  @ Thu, 14 Jun 2018 18:32:58: #1 read treatment tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:33:13:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:33:27:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:33:42:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:33:54:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:34:04: #1.2 read input tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:34:19:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:34:33:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:34:48:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:02:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:16:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:31:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:42: #1 tag size is determined as 60 bps \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:42: #1 tag size = 60 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:42: #1  total tags in treatment: 4917956 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:42: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:42: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1  tags after filtering in treatment: 4917956 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1  Redundant rate of treatment: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1  total tags in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1  tags after filtering in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1  Redundant rate of control: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #1 finished! \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #2 Build Peak Model... \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #2 Skipped... \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #2 Use 287 as fragment length \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #3 Call peaks... \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #3 Call peaks with given -log10pvalue cutoff: 1.30103 ... \n",
      "INFO  @ Thu, 14 Jun 2018 18:35:43: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Thu, 14 Jun 2018 18:36:37: #3 Call peaks for each chromosome... \n",
      "INFO  @ Thu, 14 Jun 2018 18:36:50: #4 Write output xls file... 182C_S18_peaks.xls \n",
      "INFO  @ Thu, 14 Jun 2018 18:36:50: #4 Write peak in narrowPeak format file... 182C_S18_peaks.narrowPeak \n",
      "INFO  @ Thu, 14 Jun 2018 18:36:50: #4 Write summits bed file... 182C_S18_summits.bed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Thu, 14 Jun 2018 18:36:50: Done! \n",
      "Run pipeline_176C_INPUT.sh ...\n",
      "Estimate fragment size ...\n",
      "    the estimated d is 291 \n",
      "Save results in file names started with 176C_INPUT\n",
      "Call peaks ...\n",
      "INFO  @ Thu, 14 Jun 2018 18:38:44: \n",
      "# Command line: callpeak -t /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam -c /home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam -f BAM -g 121576530 --keep-dup 1 -n 176C_INPUT --nomodel -p 0.05 --extsize 291\n",
      "# ARGUMENTS LIST:\n",
      "# name = 176C_INPUT\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "# control file = ['/home/feng/data/syno3_PW/ChIP-seq/Mapped_data/176C/INPUT-379_S21/INPUT-379_S21_raw_bowtie2_TAIR10_ensembl_nomixed_sorted_rmdup_picard.bam']\n",
      "# effective genome size = 1.22e+08\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# pvalue cutoff = 5.00e-02\n",
      "# qvalue will not be calculated and reported as -1 in the final output.\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      " \n",
      "INFO  @ Thu, 14 Jun 2018 18:38:44: #1 read tag files... \n",
      "INFO  @ Thu, 14 Jun 2018 18:38:44: #1 read treatment tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:38:59:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:39:13:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:39:23:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:39:29:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:39:38:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:39:48:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:39:57: #1.2 read input tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:04:  1000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:15:  2000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:22:  3000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:29:  4000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:36:  5000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:45:  6000000 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:50: #1 tag size is determined as 75 bps \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:50: #1 tag size = 75 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:50: #1  total tags in treatment: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:50: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:50: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1  tags after filtering in treatment: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1  Redundant rate of treatment: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1  total tags in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1 user defined the maximum tags... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1  tags after filtering in control: 6811379 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1  Redundant rate of control: 0.00 \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #1 finished! \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #2 Build Peak Model... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #2 Skipped... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #2 Use 291 as fragment length \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #3 Call peaks... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #3 Call peaks with given -log10pvalue cutoff: 1.30103 ... \n",
      "INFO  @ Thu, 14 Jun 2018 18:40:51: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Thu, 14 Jun 2018 18:41:51: #3 Call peaks for each chromosome... \n",
      "INFO  @ Thu, 14 Jun 2018 18:42:18: #4 Write output xls file... 176C_INPUT_peaks.xls \n",
      "INFO  @ Thu, 14 Jun 2018 18:42:18: #4 Write peak in narrowPeak format file... 176C_INPUT_peaks.narrowPeak \n",
      "INFO  @ Thu, 14 Jun 2018 18:42:18: #4 Write summits bed file... 176C_INPUT_summits.bed \n",
      "INFO  @ Thu, 14 Jun 2018 18:42:18: Done! \n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py summary/peaks/182C_S15_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > small_182C_S15.narrowPeak.txt\n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py summary/peaks/182C_S16_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > small_182C_S16.narrowPeak.txt\n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py summary/peaks/182C_S17_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > small_182C_S17.narrowPeak.txt\n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py summary/peaks/182C_S18_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > small_182C_S18.narrowPeak.txt\n",
      "python /media/pw_synology3/Software/chip-summary/depend/script/select_peaks.py summary/peaks/176C_INPUT_peaks.narrowPeak fc=1.5 q=0.001 p=0.01 > small_176C_INPUT.narrowPeak.txt\n",
      "... make html page summary.html\n",
      "Study: 6595 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "Study: 2957 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "Study: 6557 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "Study: 2155 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S15_1.txt > 176C_INPUT_vs_182C_S15_1_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S15_2.txt > 176C_INPUT_vs_182C_S15_2_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S15_3.txt > 176C_INPUT_vs_182C_S15_3_GOenrichment.txt\n",
      "Study: 6595 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S16_1.txt > 176C_INPUT_vs_182C_S16_1_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S16_2.txt > 176C_INPUT_vs_182C_S16_2_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S16_3.txt > 176C_INPUT_vs_182C_S16_3_GOenrichment.txt\n",
      "Study: 2957 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S17_1.txt > 176C_INPUT_vs_182C_S17_1_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S17_2.txt > 176C_INPUT_vs_182C_S17_2_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S17_3.txt > 176C_INPUT_vs_182C_S17_3_GOenrichment.txt\n",
      "Study: 6557 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S18_1.txt > 176C_INPUT_vs_182C_S18_1_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S18_2.txt > 176C_INPUT_vs_182C_S18_2_GOenrichment.txt\n",
      "Study: 0 vs. Population 33239\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hui/software/goatools/goatools/scripts/find_enrichment.py\", line 124, in <module>\n",
      "    overlap = float(len(study & pop)) / len(study)\n",
      "ZeroDivisionError: float division by zero\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 176C_INPUT_vs_182C_S18_3.txt > 176C_INPUT_vs_182C_S18_3_GOenrichment.txt\n",
      "Study: 2155 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S16_1.txt > 182C_S15_vs_182C_S16_1_GOenrichment.txt\n",
      "Study: 4022 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S16_2.txt > 182C_S15_vs_182C_S16_2_GOenrichment.txt\n",
      "Study: 2573 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S16_3.txt > 182C_S15_vs_182C_S16_3_GOenrichment.txt\n",
      "Study: 384 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S17_1.txt > 182C_S15_vs_182C_S17_1_GOenrichment.txt\n",
      "Study: 1456 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S17_2.txt > 182C_S15_vs_182C_S17_2_GOenrichment.txt\n",
      "Study: 5139 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S17_3.txt > 182C_S15_vs_182C_S17_3_GOenrichment.txt\n",
      "Study: 1418 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S18_1.txt > 182C_S15_vs_182C_S18_1_GOenrichment.txt\n",
      "Study: 5015 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S18_2.txt > 182C_S15_vs_182C_S18_2_GOenrichment.txt\n",
      "Study: 1580 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S15_vs_182C_S18_3.txt > 182C_S15_vs_182C_S18_3_GOenrichment.txt\n",
      "Study: 575 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S16_vs_182C_S17_1.txt > 182C_S16_vs_182C_S17_1_GOenrichment.txt\n",
      "Study: 385 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S16_vs_182C_S17_2.txt > 182C_S16_vs_182C_S17_2_GOenrichment.txt\n",
      "Study: 2572 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S16_vs_182C_S17_3.txt > 182C_S16_vs_182C_S17_3_GOenrichment.txt\n",
      "Study: 3985 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S16_vs_182C_S18_1.txt > 182C_S16_vs_182C_S18_1_GOenrichment.txt\n",
      "Study: 1775 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S16_vs_182C_S18_2.txt > 182C_S16_vs_182C_S18_2_GOenrichment.txt\n",
      "Study: 1182 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S16_vs_182C_S18_3.txt > 182C_S16_vs_182C_S18_3_GOenrichment.txt\n",
      "Study: 973 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S17_vs_182C_S18_1.txt > 182C_S17_vs_182C_S18_1_GOenrichment.txt\n",
      "Study: 4977 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S17_vs_182C_S18_2.txt > 182C_S17_vs_182C_S18_2_GOenrichment.txt\n",
      "Study: 1580 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "bash /media/pw_synology3/Software/chip-summary/depend/script/fe.sh 182C_S17_vs_182C_S18_3.txt > 182C_S17_vs_182C_S18_3_GOenrichment.txt\n",
      "Study: 575 vs. Population 33239\n",
      "Propagating term counts to parents ..\n",
      "terms not found: set(['GO:0022627', 'GO:0022625'])\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!chmod +x *.py\n",
    "!./main.py 182C_Ath.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pw_synology3/PW_HiSeq_data/ChIP-seq/PAIRWISE_COMPARISONS/182C\r\n"
     ]
    }
   ],
   "source": [
    "!readlink -f /home/feng/data/syno3_PW/ChIP-seq/PAIRWISE_COMPARISONS/182C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR='/home/feng/data/syno3_PW/ChIP-seq/PAIRWISE_COMPARISONS/182C'\n",
    "!cp -R \"TITLE=182C_Ath_PAIRWISE_COMPARE=Y_FC=1.5_QVALUE=0.001_TARGET_RANGE=3000_PVALUE=0.01\" {OUTDIR}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
