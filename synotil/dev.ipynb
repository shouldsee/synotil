{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is in ipython: 1\n",
      "is in ipython: 1\n",
      "[WARN] pymisca.vis_util cannot find network\n"
     ]
    }
   ],
   "source": [
    "import scipy.cluster.hierarchy as sphier\n",
    "import scipy.spatial.distance as spdist\n",
    "import pymisca.vis_util as pyvis\n",
    "import pymisca.util as pyutil\n",
    "plt = pyvis.plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spdist.squareform(np.ones((3,3)),checks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sphier\n",
    "import scipy.spatial.distance as spdist\n",
    "import pymisca.vis_util as pyvis\n",
    "import pymisca.util as pyutil\n",
    "plt = pyvis.plt\n",
    "\n",
    "# sphier.dendrogram??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting qcplots.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qcplots.py\n",
    "# import mapplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sphier\n",
    "import scipy.spatial.distance as spdist\n",
    "import pymisca.vis_util as pyvis\n",
    "import pymisca.util as pyutil\n",
    "plt = pyvis.plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def qc_dist(D,vlim=None,silent=1,axs = None,\n",
    "            cutoff=0.75,reorder = 1,method='average',\n",
    "            distance_sort='descending',level=5):\n",
    "    '''Plot a distance matrix. Perform hierarchical clustering if reorder == True\n",
    "'''\n",
    "    if D.ndim == 1:\n",
    "        D = spdist.squareform(D)\n",
    "    if reorder:\n",
    "        D_1d = spdist.squareform(D,checks=0)\n",
    "        K = sphier.linkage(D_1d,method=method)\n",
    "        \n",
    "        if isinstance( cutoff,float):\n",
    "            par = {'height':cutoff}\n",
    "        elif isinstance( cutoff,int):\n",
    "            par = {'n_clusters':cutoff}\n",
    "            \n",
    "        dendo = sphier.dendrogram(K,no_plot=1,distance_sort=distance_sort,)\n",
    "        od = dendo['leaves'][::-1]\n",
    "        clu = sphier.cut_tree(K,**par).ravel()\n",
    "        \n",
    "        #### Sort cluster as dendogram shows\n",
    "        mapper = {k:i  for i,(k,_) in enumerate(pyutil.itertools.groupby(clu[od]))}        \n",
    "        clu = map(mapper.get, clu)\n",
    "#         od = np.argsort(clu)\n",
    "        D = D[od][:,od]    \n",
    "    else:\n",
    "        clu = np.arange(len(D))\n",
    "    \n",
    "    if not silent:\n",
    "        if axs is None:\n",
    "            fig,axs= plt.subplots(1,3,figsize=[14,4]);\n",
    "            \n",
    "        axs=axs.ravel(); i = -1\n",
    "        \n",
    "        i+=1;plt.sca(axs[i]);ax=axs[i]\n",
    "        pyvis.histoLine(D.ravel(),xlim=vlim)\n",
    "        plt.grid()\n",
    "        plt.xlabel('distance')\n",
    "        plt.ylabel('count')\n",
    "\n",
    "\n",
    "        i+=1;plt.sca(axs[i]);ax=axs[i]\n",
    "        if reorder:\n",
    "            sphier.dendrogram(K,ax=ax,orientation='left',distance_sort=distance_sort,\n",
    "                             truncate_mode='level',p=level,\n",
    "                             no_labels=1);    \n",
    "            if isinstance( cutoff,float):         \n",
    "                plt.vlines(cutoff,*ax.get_ylim(),linestyles='--')\n",
    "\n",
    "        i+=1;plt.sca(axs[i]);ax=axs[i]\n",
    "        pyvis.heatmap(D,cname='distance',ax=ax,vlim=vlim)\n",
    "        pyvis.hide_axis(ax)\n",
    "\n",
    "    return clu,axs\n",
    "\n",
    "import PanelPlot as spanel\n",
    "import pandas as pd\n",
    "def make_compareClus(tks,stats = []):\n",
    "    if not isinstance(tks,list):\n",
    "        tks = [tks]\n",
    "    def compareClus(clus,tks=tks,stats0=stats, figsize=[14,5],\n",
    "                    shortName=0,L = None,\n",
    "                    how= 'left',**kwargs):\n",
    "\n",
    "#         stats0 = \n",
    "        cluTracks = map(spanel.fixCluster,clus)\n",
    "        \n",
    "        tracks = cluTracks + tks\n",
    "\n",
    "        pp =spanel.panelPlot(\n",
    "            tracks\n",
    "        )\n",
    "\n",
    "#         stats = pd.concat(clus + stats,axis=1)\n",
    "        L = len(clus) if L is None else L\n",
    "#         L = len(stats.columns)\n",
    "        figs = []\n",
    "        for coli in range(L):\n",
    "            ind = pyutil.escalIndex(L,coli)\n",
    "            ind = [coli]\n",
    "            statsc = pd.concat([clus[coli]] + stats0,axis=1)\n",
    "#             statsc = stats.iloc[:,ind]\n",
    "        #     statsc = stats.iloc[]\n",
    "        #     statsc = stats.columns\n",
    "            pp = spanel.panelPlot(tracks,)\n",
    "            fig = pp.render(order=statsc,shortName=shortName\n",
    "                                                  ,figsize=figsize,how=how)\n",
    "#             fig = plt.gcf()\n",
    "            figs +=[fig]\n",
    "        #     pp = spanel.panelPlot(tracks,).render(order=stats.iloc[:,::-1])\n",
    "        return tracks,figs\n",
    "    return compareClus\n",
    "\n",
    "\n",
    "# import scipy.cluster.hierarchy as sphier\n",
    "\n",
    "import sklearn.metrics as skmet\n",
    "def worker_cut_tree(nClu,Z=None):\n",
    "    print nClu,\n",
    "    if nClu <= 1:\n",
    "        res = None\n",
    "    else:\n",
    "        res = sphier.cut_tree( Z,n_clusters=nClu)\n",
    "    return res\n",
    "def worker_silhouette(clu,Ds=None):\n",
    "    if clu is None:\n",
    "        res = None\n",
    "    else:\n",
    "        nClu = clu.max() + 1\n",
    "        print nClu,\n",
    "    #     clu = sphier.cut_tree( Z,n_clusters=nClu)\n",
    "        S =skmet.silhouette_score(Ds, clu,metric='precomputed')\n",
    "        res = (nClu,S)\n",
    "    return res\n",
    "\n",
    "def qc_silhouette(D,\n",
    "#                   nClu = 40                 \n",
    "method = 'complete',\n",
    "nClu = 40,\n",
    "NCORE=10,\n",
    "silent=1,\n",
    "axs= None\n",
    "):\n",
    "    Ds = D\n",
    "\n",
    "    if D.ndim == 2:\n",
    "        D = spdist.squareform(D,checks=0)\n",
    "    if Ds.ndim != 2:\n",
    "        Ds = spdist.squareform(Ds,checks=0)\n",
    "\n",
    "    # D = D_mse\n",
    "    Z = sphier.linkage(D,method= method,)\n",
    "    lst = []\n",
    "    clus = []\n",
    "    nClus = range(0,nClu)\n",
    "    worker = pyutil.functools.partial(\n",
    "        worker_cut_tree,\n",
    "        Z=Z)    \n",
    "    clus = pyutil.mp_map(worker, \n",
    "              nClus,n_cpu=NCORE)\n",
    "    \n",
    "    worker = pyutil.functools.partial(\n",
    "        worker_silhouette,\n",
    "        Ds = Ds)\n",
    "#     lst = []\n",
    "    lst = pyutil.mp_map(worker,\n",
    "                       clus,\n",
    "#                        n_cpu=min(NCORE,4)\n",
    "                       n_cpu=1\n",
    "                       )\n",
    "\n",
    "    lst = [x for x in lst if x is not None]\n",
    "    shind = lst\n",
    "    shind= np.array(shind)\n",
    "    if not silent:\n",
    "        if axs is None:\n",
    "            fig,axs= plt.subplots(1,1,figsize=[6,4]);\n",
    "            axs = [axs]\n",
    "        ax = axs[0]\n",
    "        X,Y = shind.T\n",
    "        ax.plot(X,Y)\n",
    "        # pyvis.abline()\n",
    "        ax.set_xlim(left=0)\n",
    "        wid = 3; rid = wid//2\n",
    "        movavg = map(np.mean,pyutil.window(Y,n=wid,step=1,),)        \n",
    "        ax.plot(X[rid:-rid], movavg,'x--',\n",
    "               label = 'Moving average')\n",
    "        ax.grid(1)\n",
    "        ax.legend()\n",
    "\n",
    "    return shind\n",
    "\n",
    "def qc_cumAvg(X,axis=0,\n",
    "             silent=1,\n",
    "             axs=None,\n",
    "             nMax = int(1E6),\n",
    "              ybin = None,\n",
    "#               axiS = [2,None,None]\n",
    "             ):\n",
    "    '''Calcuate average and standard error for bootstrapped statistics.\n",
    "'''\n",
    "# axis = 0\n",
    "#     X = egList[:5]\n",
    "    X = np.array(X)\n",
    "    X = np.moveaxis(X,axis,0)\n",
    "    # L = np.shape(X)[axis]\n",
    "    X = np.reshape(X,(len(X),-1))\n",
    "    if len(X.T) > nMax:\n",
    "        ind = np.random.randint(0,len(X.T),nMax)\n",
    "        X = X[:,ind]\n",
    "\n",
    "    L = len(X)\n",
    "    Lx = (1+np.arange(L))[:,None]\n",
    "\n",
    "    Ex = np.cumsum(X,axis=axis)/Lx\n",
    "    Ex2 = np.cumsum(np.square(X),axis=axis)/Lx\n",
    "\n",
    "    M = Ex\n",
    "    VAR = (Ex2 - np.square(Ex) )\n",
    "    SD = np.sqrt(VAR)\n",
    "    SE = SD/np.sqrt(Lx)\n",
    "    CV = SE/M; CV = abs(CV)\n",
    "    Lx = np.broadcast_to(Lx,SE.shape) \n",
    "    if not silent:\n",
    "        if axs is None:\n",
    "            fig,axs= plt.subplots(1,3,figsize=[14,4]);\n",
    "            axs=[None,None,axs[0]]\n",
    "        X,Y = Lx,CV\n",
    "        ybin = np.linspace(*pyutil.span(Y,99.),num=80) if ybin is None else ybin\n",
    "        xbin = np.arange(0.5,L+1,1)\n",
    "        pyvis.qc_2var(X,Y,\n",
    "#                       axs=axs,\n",
    "                      xbin=xbin,ybin = ybin,\n",
    "                      ylab=r'$\\left| {StdErr} / {Mean} \\right |$',\n",
    "                     xlab='sample size',\n",
    "                      axs=axs,\n",
    "                     )\n",
    "    return (M,SE,CV,Lx),axs\n",
    "\n",
    "\n",
    "def qc_Avg(C, silent=1,axis=1,\n",
    "#            nMax = 150, ### depracated size check\n",
    "           **kwargs):\n",
    "    \n",
    "#     if axs is None:\n",
    "#         if not silent:\n",
    "#             fig,axs= plt.subplots(1,3,figsize=[14,3])\n",
    "    C = np.array(C)\n",
    "#     assert C.shape[axis]<nMax\n",
    "    MEAN = C.mean(axis=axis,)\n",
    "    STD = C.std(axis=axis,)\n",
    "    # plt.hist(X) def parseBedmap\n",
    "    # plt.hist(X[1])\n",
    "#     X = MEAN[None,:]\n",
    "    X = MEAN\n",
    "    MIN,MAX = X.min(),np.percentile(X,99)\n",
    "    BINS = np.linspace(MIN,MAX,100)\n",
    "    CV = STD/MEAN\n",
    "    if not silent:\n",
    "        xs,ys = MEAN,STD\n",
    "        axs = pyvis.qc_2var(xs,ys,xlab='$E(X)$',ylab='$Std(X)$',\n",
    "                            **kwargs)\n",
    "    else:\n",
    "        axs = []\n",
    "    return (MEAN,STD,CV),axs\n",
    "def qcAvg(*args,**kwargs):\n",
    "    '''Legacy support''' \n",
    "    return qc_Avg(*args,**kwargs)\n",
    "\n",
    "def qc_meanVar( C, clu, axs=None,xlim=None,ylim=None,silent=0):\n",
    "    ''' C of shape (n_gene, n_condition)\n",
    "    Points colored by cluster\n",
    "    '''\n",
    "    clu = np.array(clu).ravel()\n",
    "    nClu = np.max(clu)+1\n",
    "    if axs is None:\n",
    "        fig,axs= plt.subplots(1,3,figsize=[14,3])\n",
    "    for ci in range(nClu):\n",
    "        idx = np.where(clu==ci)[0]\n",
    "        CC = C[idx,:]\n",
    "        STAT,axs = qcAvg(CC, axs=axs, silent=silent)\n",
    "    ax = axs[1]\n",
    "#     ax.set_alpha(0.5)\n",
    "    MEAN = C.mean(axis=1,keepdims=1).squeeze()\n",
    "    STD = C.std(axis=1,keepdims = 1).squeeze()\n",
    "    \n",
    "    xlim = xlim if xlim is not None else np.span(MEAN,99.9)\n",
    "    ylim = ylim if ylim is not None else np.span(STD,99.9)\n",
    "    \n",
    "    xlim = np.span(MEAN,99.)\n",
    "    ylim = np.span(STD,99.)\n",
    "#     for ax in axs:\n",
    "    ax = axs[0]\n",
    "    ax.set_xlim(xlim);#ax.set_ylim(ylim)\n",
    "    ax = axs[1]\n",
    "    ax.set_xlim(xlim);ax.set_ylim(ylim)\n",
    "    ax = axs[2]\n",
    "    ax.set_xlim(xlim);ax.set_ylim(ylim)\n",
    "    return ((MEAN,STD,STD/MEAN),axs)\n",
    "\n",
    "def qc_pileUp(bwt,ax=None,silent =0,\n",
    "             sigMax = 20,\n",
    "             ):\n",
    "    '''bwt: A dataFrame containing the peak regions from a bigWig track\n",
    "    sigMax: throw away peaks with average above this maximum\n",
    "    sigMax: clip the signal at this maximum \n",
    "'''\n",
    "    if bwt.index.duplicated().any():\n",
    "        bwt =bwt.reset_index(drop=1,inplace=False)\n",
    "    bwt.qc_Avg()\n",
    "    index = bwt.summary.query('M<%d'%sigMax).index\n",
    "    bwtc = bwt.reindex(index)\n",
    "    xs = bwt.columns\n",
    "\n",
    "    (M,SD,CV), _ = qc_Avg(bwtc.T,nMax=1E100)\n",
    "    SE = SD/len(M)**0.5\n",
    "\n",
    "    if not silent:\n",
    "        if ax is None:\n",
    "            fig,ax0s= plt.subplots(1,3,figsize=[14,3])    \n",
    "            i = -1\n",
    "            i += 1;ax=axs[i]; plt.sca(ax)\n",
    "        else:\n",
    "            axs = None\n",
    "        plt.plot(M,'b')\n",
    "        plt.plot(M+2*SE, 'b--', alpha=0.5)\n",
    "        plt.plot(M-2*SE, 'b--', alpha=0.5)\n",
    "#         plt.title(pyutil.basename(fname))\n",
    "        plt.grid(1)\n",
    "        \n",
    "    return (M, SE), ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting __init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile __init__.py\n",
    "import CountMatrix as scount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting norm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile norm.py\n",
    "import numpy as np\n",
    "import pymisca.util as pyutil\n",
    "\n",
    "import sklearn.decomposition as skdecomp\n",
    "pd = pyutil.pd\n",
    "import CountMatrix as scount\n",
    "# import util as util\n",
    "\n",
    "\n",
    "def stdNorm(X):\n",
    "    deco = 0\n",
    "    if isinstance(X,scount.countMatrix):\n",
    "        deco =1\n",
    "        df = X \n",
    "        \n",
    "    X = meanNorm(X)\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    X = X.copy()\n",
    "    assert isinstance(X,np.ndarray)\n",
    "    STD = np.std(X,axis=1,keepdims=1); pos = np.squeeze(STD>0);\n",
    "    X[pos] = X[pos]/STD[pos]\n",
    "\n",
    "    if deco:\n",
    "        X = df.setDF(X)\n",
    "        X.param['normF'] = 'stdNorm'\n",
    "    return X\n",
    "def meanNorm(X):\n",
    "    deco = 0\n",
    "    if isinstance(X,scount.countMatrix):\n",
    "        deco =1\n",
    "        df = X \n",
    "        \n",
    "    if isinstance(X,pd.Series):\n",
    "        X = X.values\n",
    "        X = (X - X.mean())\n",
    "    else:\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        assert isinstance(X,np.ndarray)\n",
    "        X = (X-X.mean(axis=1,keepdims=1))\n",
    "        \n",
    "    param = getattr(X,'param',{})    \n",
    "    param['normF'] = 'meanNorm'\n",
    "#     X.param = param\n",
    "    \n",
    "    if deco:\n",
    "        X = df.setDF(X)\n",
    "        X.param['normF'] = 'meanNorm'        \n",
    "    return X\n",
    "\n",
    "def meanNormProj(X):\n",
    "    deco = 0\n",
    "    if isinstance(X,scount.countMatrix):\n",
    "        deco =1\n",
    "        df = X\n",
    "        \n",
    "    X = meanNorm(X)\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values    \n",
    "        \n",
    "    D = X.shape[1]\n",
    "    Wn  = pyutil.meanNormBasis(D,orthonormal =1 )\n",
    "    X = X.dot(Wn.T)\n",
    "    \n",
    "    param = getattr(X,'param',{})    \n",
    "    param['normF'] = 'meanNormProj'\n",
    "#     X.param = param\n",
    "\n",
    "    if deco:\n",
    "        X = df.setDF(X)\n",
    "        X.param['normF'] = 'meanNormProj'        \n",
    "    return X\n",
    "import sklearn.decomposition as skdecomp\n",
    "def meanNormPCA(X,cutoff=1.0, withModel=0):\n",
    "    name = 'meanNormPCA'\n",
    "    deco = 0\n",
    "    if isinstance(X,scount.countMatrix):\n",
    "        deco =1\n",
    "        df = X\n",
    "        \n",
    "    X = meanNorm(X)\n",
    "    X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "    \n",
    "    X0 = X\n",
    "    mdl = skdecomp.PCA()\n",
    "    mdl.fit(X)\n",
    "    \n",
    "    X = mdl.transform(X)\n",
    "    \n",
    "    first = np.cumsum(mdl.explained_variance_ratio_) >= cutoff\n",
    "    idx   =np.argmax(first) + 1\n",
    "    mdl.components_ = mdl.components_[:idx]\n",
    "#     mdl.mean_ = mdl.mean_[:,idx]\n",
    "\n",
    "    X = X[:,:idx]\n",
    "        \n",
    "    param = getattr(X,'param',{})    \n",
    "    param['normF'] = name\n",
    "#     X.param = param\n",
    "\n",
    "    if deco:\n",
    "        X = df.setDF(X)\n",
    "        X.param['normF'] = name     \n",
    "    if withModel:\n",
    "        return (X,mdl,X0)\n",
    "    else:\n",
    "        return X\n",
    "def ctNorm(X):\n",
    "    X = (X-X.mean(axis=1,keepdims=1))\n",
    "    return X\n",
    "def identityNorm(X):\n",
    "    param = getattr(X,'param',{})    \n",
    "    param['normF'] = 'identityNorm'\n",
    "#     X.param = param    \n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting qcmsg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qcmsg.py\n",
    "\n",
    "def msgGMM(model = None, train_data = None,name='test',**kwargs):\n",
    "    mdl = model\n",
    "    s = '''\n",
    "Name:{name}\n",
    "Converged:{cvg}\n",
    "min_logL: {logL}\n",
    "(lower-bound of) MEAN logL :{mlogL}'''.format(\n",
    "        name=name,\n",
    "         cvg=mdl.converged_,\n",
    "         logL = mdl.lower_bound_,\n",
    "         mlogL=mdl.lower_bound_/len(train_data) if not train_data is None else mdl.lower_bound_\n",
    "                                )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modelRoutine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modelRoutine.py\n",
    "\n",
    "import sklearn.mixture as skmix\n",
    "import pymisca.util as pyutil\n",
    "np = pyutil.np; pd = pyutil.pd\n",
    "import os\n",
    "import qcmsg\n",
    "import CountMatrix as scount\n",
    "import qcplots\n",
    "\n",
    "def fit_BGM(C,\n",
    "            ALI = 'Test',\n",
    "#             DIR = ''\n",
    "#             normF = identityNorm,\n",
    "            stdPer = 0,\n",
    "            rowName=None,\n",
    "            colName=None,\n",
    "            nClu = 25,\n",
    "            maxIt = 1000,\n",
    "            algo = 'DPGMM',\n",
    "            DIR= '.',\n",
    "#            algoLst = ['DPGMM'],\n",
    "            alpha = .1,\n",
    "            covariance_type = 'diag',\n",
    "            fixMean = 0,\n",
    "            reorder=1,\n",
    "            model_only =0,\n",
    "            random_state= None,\n",
    "            dbg=0,\n",
    "#             covariance_type = None,\n",
    "#             **kwargs\n",
    "           ):\n",
    "    '''\n",
    "Fit an BayesianGaussianMixture() model from sklearn\n",
    "'''\n",
    "#     if algoLst is None:\n",
    "#         algoLst = ['DPGMM','DDGMM','GMM',]    \n",
    "    try:\n",
    "        DIR,ALI = ALI.rsplit('/',1)\n",
    "    except:\n",
    "        DIR= DIR\n",
    "    os.system('mkdir -p %s'%(DIR))\n",
    "    \n",
    "    \n",
    "    ###### Manage meta attributes of the model ########\n",
    "    param = {\n",
    "            'fixMean':fixMean,\n",
    "             'stdPer':stdPer,\n",
    "             'nClu':nClu,\n",
    "             'genre':algo,\n",
    "             'covarianceType': covariance_type,\n",
    "              'maxIt' : maxIt,\n",
    "              'randomState':random_state,\n",
    "         }\n",
    "    param.update(getattr(C,'param',{}))\n",
    "    \n",
    "    ####### Convert to numpy arrary ######\n",
    "    if isinstance(C,pd.DataFrame):\n",
    "        if  ALI=='Test':\n",
    "            ALI = getattr(C,'name','Test') \n",
    "\n",
    "        rowName,colName,C = C.index.values, C.columns, C.values\n",
    "        pass\n",
    "    \n",
    "    ##### Old routine that filter by STD ###########\n",
    "    if stdPer > 0 :\n",
    "        assert stdPer < 100,'Percentile must < 100, Got %d instead'%stdPer\n",
    "        (MEAN,STD,CV),_ = qc_Avg(C)\n",
    "        pIdx = STD > np.percentile(STD, stdPer)        \n",
    "        rowName = np.array(rowName)[pIdx]; C = C[pIdx]\n",
    "    print '[ALI]=',ALI\n",
    "    nFeat = C.shape[-1]\n",
    "        \n",
    "    #####====== Defnitions of fitters=========#######\n",
    "    \n",
    "    ###### Arguments shared among fitters ######\n",
    "    common = {'n_components': nClu,\n",
    "          'verbose':2,\n",
    "         'max_iter':maxIt,\n",
    "             'covariance_type':covariance_type,\n",
    "              'random_state':random_state,\n",
    "             }\n",
    "    if fixMean:\n",
    "        mean_precision_prior = 1E-128\n",
    "        mean_prior = [0.]*nFeat\n",
    "    else:\n",
    "        mean_precision_prior  = None\n",
    "        mean_prior = None\n",
    "        \n",
    "    ####### List of fitters ######\n",
    "    mdlLst = {'DPGMM':skmix.BayesianGaussianMixture(weight_concentration_prior_type='dirichlet_process',\n",
    "                                        weight_concentration_prior=alpha,\n",
    "                                        mean_precision_prior = mean_precision_prior,\n",
    "                                        mean_prior = mean_prior,\n",
    "                                       **common),\n",
    "          'GMM':skmix.GaussianMixture(**common),\n",
    "          'DDGMM':skmix.BayesianGaussianMixture(weight_concentration_prior_type='dirichlet_distribution',\n",
    "                                        weight_concentration_prior=alpha,\n",
    "                                        mean_precision_prior = mean_precision_prior,\n",
    "                                        mean_prior = mean_prior,\n",
    "                                       **common),\n",
    "         }\n",
    "    \n",
    "    \n",
    "    ############# Select model by \"algo\"####\n",
    "    X = C\n",
    "    if dbg >= 2:\n",
    "        qcplots.qc_Avg(C,silent=0)\n",
    "    print pyutil.qc_matrix(X)\n",
    "    mdl = mdlLst.get(algo,None)\n",
    "    assert mdl is not None, 'Algorithm %s not found '%algo\n",
    "    \n",
    "    NAME = '%s_%s'%(ALI,pyutil.dict2flat(param))    \n",
    "    print '[MSG] Now Fitting Model:%s'%NAME\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####### Meta data of the training Data #######\n",
    "    d = {'name': NAME,\n",
    "         'train_data':X,\n",
    "         'colName':colName,\n",
    "         'rowName':rowName,\n",
    "         'param':param,\n",
    "       }\n",
    "    \n",
    "    \n",
    "    ##### Fitting model and caching the result to specified DIR/NAME ####\n",
    "    try:\n",
    "        logFile = open('%s/%s.log'%(DIR,NAME),'w',0)\n",
    "        with pyutil.RedirectStdStreams(logFile):\n",
    "            mdl.fixMean= fixMean\n",
    "            mdl.fit(X)\n",
    "#             reorderByMSQ(mdl)\n",
    "            if reorder:\n",
    "                mdl.reorderByMSQ()\n",
    "            d.update({'suc':1,'model':mdl})\n",
    "#             logFile.close()\n",
    "        print \"[SUCC] to fit Model:%s\"%(NAME,)\n",
    "        print qcmsg.msgGMM(mdl)\n",
    "    except Exception as e:\n",
    "        print \"[FAIL] to fit Model:%s due to :'%s'\"%(NAME,e)\n",
    "        d.update({'suc':0})\n",
    "    if model_only:\n",
    "        d['train_data'] = None\n",
    "        d['rowName'] = None\n",
    "        d['colName'] = None\n",
    "    np.save('%s/%s'%(DIR.rstrip('/'),NAME),d)\n",
    "    d = scount.countMatrix.from_dict(d)\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dio.py\n",
    "import CountMatrix as scount\n",
    "import pymisca.util as pyutil\n",
    "\n",
    "bedHeader = '''\n",
    "0:chrom\n",
    "1:start\n",
    "2:end\n",
    "3:acc\n",
    "4:score\n",
    "5:strand\n",
    "6:FC\n",
    "7:neglogPval\n",
    "8:neglogQval\n",
    "9:summit\n",
    "'''.strip().splitlines()\n",
    "bedHeader = [x.split(':')[1] for x in bedHeader] \n",
    "\n",
    "\n",
    "def readChipPeak(fname,**kwargs):\n",
    "    '''CountMatrix.geneList is buggy at the moment hence needed to be converted back into \n",
    "    CountMatrix.countMatrix\n",
    "'''\n",
    "    df = scount.countMatrix.from_DataFrame(fname=fname,ext='tsv',index_col='geneAcc',addFname=0,**kwargs)\n",
    "    df= df.toGeneList()\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_peak(fname,ext='tsv',header=None,guess_index=0,**kwargs):\n",
    "    df = pyutil.readData(fname,ext=ext,header=header,guess_index=guess_index,**kwargs)\n",
    "    df.columns = bedHeader + list(df.columns)[len(bedHeader):]\n",
    "    return df\n",
    "    \n",
    "\n",
    "def npk_expandSummit(df=None,radius=200,fname = None,clip = 1):\n",
    "    '''\n",
    "    Expand the summit regions of a .narrowPeak dataFrame\n",
    "'''\n",
    "    if df is None:\n",
    "        df = extract_peak(fname)\n",
    "    df['abs_summit'] = df.start + df.summit\n",
    "    st = df.strand\n",
    "    df.start = (df.abs_summit - radius)\n",
    "    df.end  = df.abs_summit + radius \n",
    "    df.drop('abs_summit',1,inplace=True)\n",
    "    if clip:\n",
    "        df.start = df.start.clip_lower(0)\n",
    "    if fname is not None:\n",
    "        base = pyutil.basename(fname)\n",
    "        ofname = '%s_radius=%d.tsv' % (base,radius)\n",
    "        df.to_csv(ofname,sep='\\t',index=None,header=None)\n",
    "        return ofname\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "#     df.columns = [pyutil.basename(fname)]\n",
    "#     chipPeak = df\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "??json.dumps({},sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
